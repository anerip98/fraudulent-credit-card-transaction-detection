{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> <center> Detecting Fraudulent Credit Card Transactions </h1> </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "It is important that credit card companies are able to recognize fraudulent credit card transactions so that customers are not charged for items that they did not purchase  [$^1$](https://www.kaggle.com/mlg-ulb/creditcardfraud). \n",
    "\n",
    "\n",
    "## Data\n",
    "The [dataset](https://www.kaggle.com/mlg-ulb/creditcardfraud) contains transactions made by credit cards in September 2013 by European card-holders. This dataset presents transactions that occurred in two days, where there are 492 frauds out of 284,807 transactions. The dataset is highly unbalanced, the positive class (frauds) account for 0.172% of all transactions.\n",
    "\n",
    "It contains only numerical input variables which are the result of a PCA transformation. Unfortunately, due to confidentiality issues, the original features and more background information about the data is not provided. Features V1, V2, ... V28 are the principal components obtained with PCA, the only features which have not been transformed with PCA are 'Time' and 'Amount'. Feature 'Time' contains the seconds elapsed between each transaction and the first transaction in the dataset. The feature 'Amount' is the transaction Amount, this feature can be used for example-dependant cost-senstive learning. Feature 'Class' is the response variable and it takes value 1 in case of fraud and 0 otherwise [$^1$](https://www.kaggle.com/mlg-ulb/creditcardfraud).\n",
    "\n",
    "Given the class imbalance ratio, the classification accuracy is measured using the average classification precision. Confusion matrix accuracy is not meaningful for unbalanced classification.\n",
    "\n",
    "## Problem Statement\n",
    "Classify the transaction as fraud/not fraud using the 28 PCA transformed features provided.\n",
    "\n",
    "## Approach\n",
    "Data imbalance was handled using:\n",
    "- Voting\n",
    "- Upsampling\n",
    "- Downsampling\n",
    "\n",
    "After each imbalance handling method was applied, data was classified using logistic regression and neural network to compare accuracy of the classification problem.\n",
    "\n",
    "It is found that all 3 imbalance handling methods work equally well. \n",
    "\n",
    "## Conclusion \n",
    "Maximum average precision of 0.96 was achieved using neural networks and oversampling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import svm\n",
    "\n",
    "import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "from imblearn.over_sampling import SMOTE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('creditcard.csv','rt')as f:\n",
    "    data1 = csv.reader(f)\n",
    "    datax =[]\n",
    "    for row in data1:\n",
    "        datax.append(row)\n",
    "datax = np.array(datax)\n",
    "columns = datax[0]\n",
    "data = np.delete(datax,0,axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data dimensions:  (284807, 31)\n"
     ]
    }
   ],
   "source": [
    "print(\"data dimensions: \", data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x dimensions:  (284807, 30)\n",
      "labels:  (284807,)\n",
      "x data type:  <class 'numpy.str_'>\n"
     ]
    }
   ],
   "source": [
    "labels = data[:,30]\n",
    "x = data[:,:30]\n",
    "print(\"x dimensions: \",x.shape)\n",
    "print(\"labels: \",labels.shape)\n",
    "print(\"x data type: \",type(x[0][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 1 - train k models and apply voting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Partitioning data by class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data0x shape (284315, 30)\n",
      "data1x shape (492, 30)\n"
     ]
    }
   ],
   "source": [
    "data0 = []\n",
    "data1 = []\n",
    "for i in np.arange(x.shape[0]):\n",
    "    temp = x[i].astype(np.float)\n",
    "#     v= labels[i].astype(np.float)\n",
    "    if labels[i]==str(0):\n",
    "        data0.append(temp)\n",
    "    else:\n",
    "        data1.append(temp)\n",
    "data0x = np.array(data0)\n",
    "data1x = np.array(data1)\n",
    "print(\"data0x shape\",data0x.shape)\n",
    "print(\"data1x shape\",data1x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting class imbalance to 90:10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4428, 30)\n",
      "(492, 30)\n"
     ]
    }
   ],
   "source": [
    "p = data1x.shape[0]*9\n",
    "data0 = data0x[:p,:]\n",
    "data1 = data1x\n",
    "print(data0.shape)\n",
    "print(data1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting into train and test sets (50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_data0 shape (50, 30)\n",
      "test_data1 shape (50, 30)\n",
      "train_data0 shape (4378, 30)\n",
      "train_data1 shape (442, 30)\n"
     ]
    }
   ],
   "source": [
    "#Doing Ensemble(Taking 492 samples from data0 and making 9 training sets out of it. Then Training 9 \n",
    "#classifiers since ratio is 9:1)\n",
    "test_data0 = data0[:50,:]\n",
    "test_data1 = data1[:50,:]\n",
    "print(\"test_data0 shape\",test_data0.shape)\n",
    "print(\"test_data1 shape\",test_data1.shape)\n",
    "\n",
    "train_data0 = data0[50:,:]\n",
    "train_data1 = data1[50:,:]\n",
    "print(\"train_data0 shape\",train_data0.shape)\n",
    "print(\"train_data1 shape\",train_data1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparing training data (0) into k sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of 0 :  (442, 30)\n",
      "shape of 1 :  (442, 30)\n",
      "shape of 2 :  (442, 30)\n",
      "shape of 3 :  (442, 30)\n",
      "shape of 4 :  (442, 30)\n",
      "shape of 5 :  (442, 30)\n",
      "shape of 6 :  (442, 30)\n",
      "shape of 7 :  (442, 30)\n",
      "shape of 8 :  (442, 30)\n"
     ]
    }
   ],
   "source": [
    "split_data0 = []\n",
    "n1train=train_data1.shape[0]\n",
    "n0train=train_data0.shape[0]\n",
    "k = int(n0train/n1train)\n",
    "c = 0\n",
    "for i in np.arange(k):\n",
    "    split_data0.append(train_data0[c*n1train:(c+1)*n1train][:])\n",
    "    c=c+1\n",
    "for i in np.arange(k):\n",
    "    print(\"shape of\",i,\": \",split_data0[i].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparing testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "label0 = np.zeros((test_data0.shape[0]))\n",
    "label1 = np.ones((test_data1.shape[0]))\n",
    "test_data = np.concatenate((test_data0,test_data1),axis = 0)\n",
    "test_label = np.concatenate((label0,label1),axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Binary classification - training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 884 samples\n",
      "Epoch 1/100\n",
      "884/884 [==============================] - 1s 1ms/sample - loss: 5080.8407 - accuracy: 0.4796\n",
      "Epoch 2/100\n",
      "884/884 [==============================] - 0s 26us/sample - loss: 2772.9975 - accuracy: 0.4661\n",
      "Epoch 3/100\n",
      "884/884 [==============================] - 0s 26us/sample - loss: 601.8323 - accuracy: 0.3258\n",
      "Epoch 4/100\n",
      "884/884 [==============================] - 0s 25us/sample - loss: 4.9410 - accuracy: 0.5011\n",
      "Epoch 5/100\n",
      "884/884 [==============================] - 0s 27us/sample - loss: 5.0428 - accuracy: 0.5034\n",
      "Epoch 6/100\n",
      "884/884 [==============================] - 0s 23us/sample - loss: 3.7599 - accuracy: 0.5396\n",
      "Epoch 7/100\n",
      "884/884 [==============================] - 0s 24us/sample - loss: 2.0169 - accuracy: 0.5939\n",
      "Epoch 8/100\n",
      "884/884 [==============================] - 0s 28us/sample - loss: 2.8788 - accuracy: 0.6210\n",
      "Epoch 9/100\n",
      "884/884 [==============================] - 0s 29us/sample - loss: 1.2195 - accuracy: 0.6278\n",
      "Epoch 10/100\n",
      "884/884 [==============================] - 0s 29us/sample - loss: 1.1974 - accuracy: 0.6369\n",
      "Epoch 11/100\n",
      "884/884 [==============================] - 0s 27us/sample - loss: 1.0634 - accuracy: 0.6606\n",
      "Epoch 12/100\n",
      "884/884 [==============================] - 0s 28us/sample - loss: 0.9228 - accuracy: 0.6810\n",
      "Epoch 13/100\n",
      "884/884 [==============================] - 0s 27us/sample - loss: 0.7989 - accuracy: 0.7048\n",
      "Epoch 14/100\n",
      "884/884 [==============================] - 0s 29us/sample - loss: 0.6970 - accuracy: 0.7251\n",
      "Epoch 15/100\n",
      "884/884 [==============================] - 0s 33us/sample - loss: 0.6105 - accuracy: 0.7455\n",
      "Epoch 16/100\n",
      "884/884 [==============================] - 0s 29us/sample - loss: 0.5373 - accuracy: 0.7613\n",
      "Epoch 17/100\n",
      "884/884 [==============================] - 0s 27us/sample - loss: 0.4763 - accuracy: 0.7805\n",
      "Epoch 18/100\n",
      "884/884 [==============================] - 0s 29us/sample - loss: 0.4202 - accuracy: 0.7952\n",
      "Epoch 19/100\n",
      "884/884 [==============================] - 0s 25us/sample - loss: 0.3729 - accuracy: 0.8133\n",
      "Epoch 20/100\n",
      "884/884 [==============================] - 0s 27us/sample - loss: 0.3324 - accuracy: 0.8235\n",
      "Epoch 21/100\n",
      "884/884 [==============================] - 0s 27us/sample - loss: 0.2949 - accuracy: 0.8416\n",
      "Epoch 22/100\n",
      "884/884 [==============================] - 0s 24us/sample - loss: 0.2636 - accuracy: 0.8597\n",
      "Epoch 23/100\n",
      "884/884 [==============================] - 0s 25us/sample - loss: 0.2353 - accuracy: 0.8699\n",
      "Epoch 24/100\n",
      "884/884 [==============================] - 0s 29us/sample - loss: 0.2102 - accuracy: 0.8869\n",
      "Epoch 25/100\n",
      "884/884 [==============================] - 0s 33us/sample - loss: 0.1886 - accuracy: 0.9038\n",
      "Epoch 26/100\n",
      "884/884 [==============================] - 0s 38us/sample - loss: 0.1696 - accuracy: 0.9140\n",
      "Epoch 27/100\n",
      "884/884 [==============================] - 0s 30us/sample - loss: 0.1528 - accuracy: 0.9208\n",
      "Epoch 28/100\n",
      "884/884 [==============================] - 0s 24us/sample - loss: 0.1389 - accuracy: 0.9321\n",
      "Epoch 29/100\n",
      "884/884 [==============================] - 0s 25us/sample - loss: 0.1261 - accuracy: 0.9502\n",
      "Epoch 30/100\n",
      "884/884 [==============================] - 0s 35us/sample - loss: 0.1149 - accuracy: 0.9548\n",
      "Epoch 31/100\n",
      "884/884 [==============================] - 0s 41us/sample - loss: 0.1051 - accuracy: 0.9593\n",
      "Epoch 32/100\n",
      "884/884 [==============================] - 0s 30us/sample - loss: 0.0965 - accuracy: 0.9615\n",
      "Epoch 33/100\n",
      "884/884 [==============================] - 0s 25us/sample - loss: 0.0890 - accuracy: 0.9729\n",
      "Epoch 34/100\n",
      "884/884 [==============================] - 0s 27us/sample - loss: 0.0822 - accuracy: 0.9751\n",
      "Epoch 35/100\n",
      "884/884 [==============================] - 0s 25us/sample - loss: 0.0764 - accuracy: 0.9774\n",
      "Epoch 36/100\n",
      "884/884 [==============================] - 0s 26us/sample - loss: 0.0710 - accuracy: 0.9796\n",
      "Epoch 37/100\n",
      "884/884 [==============================] - 0s 24us/sample - loss: 0.0663 - accuracy: 0.9864\n",
      "Epoch 38/100\n",
      "884/884 [==============================] - 0s 25us/sample - loss: 0.0620 - accuracy: 0.9876\n",
      "Epoch 39/100\n",
      "884/884 [==============================] - 0s 21us/sample - loss: 0.0582 - accuracy: 0.9898\n",
      "Epoch 40/100\n",
      "884/884 [==============================] - 0s 26us/sample - loss: 0.0547 - accuracy: 0.9910\n",
      "Epoch 41/100\n",
      "884/884 [==============================] - 0s 27us/sample - loss: 0.0515 - accuracy: 0.9921\n",
      "Epoch 42/100\n",
      "884/884 [==============================] - 0s 25us/sample - loss: 0.0486 - accuracy: 0.9921\n",
      "Epoch 43/100\n",
      "884/884 [==============================] - 0s 25us/sample - loss: 0.0460 - accuracy: 0.9921\n",
      "Epoch 44/100\n",
      "884/884 [==============================] - 0s 26us/sample - loss: 0.0437 - accuracy: 0.9932\n",
      "Epoch 45/100\n",
      "884/884 [==============================] - 0s 24us/sample - loss: 0.0414 - accuracy: 0.9943\n",
      "Epoch 46/100\n",
      "884/884 [==============================] - 0s 26us/sample - loss: 0.0394 - accuracy: 0.9943\n",
      "Epoch 47/100\n",
      "884/884 [==============================] - 0s 25us/sample - loss: 0.0375 - accuracy: 0.9955\n",
      "Epoch 48/100\n",
      "884/884 [==============================] - 0s 26us/sample - loss: 0.0357 - accuracy: 0.9955\n",
      "Epoch 49/100\n",
      "884/884 [==============================] - 0s 24us/sample - loss: 0.0342 - accuracy: 0.9955\n",
      "Epoch 50/100\n",
      "884/884 [==============================] - 0s 23us/sample - loss: 0.0327 - accuracy: 0.9955\n",
      "Epoch 51/100\n",
      "884/884 [==============================] - 0s 25us/sample - loss: 0.0313 - accuracy: 0.9955\n",
      "Epoch 52/100\n",
      "884/884 [==============================] - 0s 25us/sample - loss: 0.0300 - accuracy: 0.9966\n",
      "Epoch 53/100\n",
      "884/884 [==============================] - 0s 26us/sample - loss: 0.0288 - accuracy: 0.9966\n",
      "Epoch 54/100\n",
      "884/884 [==============================] - 0s 26us/sample - loss: 0.0276 - accuracy: 0.9966\n",
      "Epoch 55/100\n",
      "884/884 [==============================] - 0s 27us/sample - loss: 0.0266 - accuracy: 0.9966\n",
      "Epoch 56/100\n",
      "884/884 [==============================] - 0s 24us/sample - loss: 0.0263 - accuracy: 0.9966\n",
      "Epoch 57/100\n",
      "884/884 [==============================] - 0s 29us/sample - loss: 0.0258 - accuracy: 0.9966\n",
      "Epoch 58/100\n",
      "884/884 [==============================] - 0s 24us/sample - loss: 0.0254 - accuracy: 0.9966\n",
      "Epoch 59/100\n",
      "884/884 [==============================] - 0s 25us/sample - loss: 0.0251 - accuracy: 0.9966\n",
      "Epoch 60/100\n",
      "884/884 [==============================] - 0s 24us/sample - loss: 0.0248 - accuracy: 0.9977\n",
      "Epoch 61/100\n",
      "884/884 [==============================] - 0s 27us/sample - loss: 0.0245 - accuracy: 0.9977\n",
      "Epoch 62/100\n",
      "884/884 [==============================] - 0s 24us/sample - loss: 0.0242 - accuracy: 0.9977\n",
      "Epoch 63/100\n",
      "884/884 [==============================] - 0s 25us/sample - loss: 0.0240 - accuracy: 0.9977\n",
      "Epoch 64/100\n",
      "884/884 [==============================] - 0s 24us/sample - loss: 0.0236 - accuracy: 0.9977\n",
      "Epoch 65/100\n",
      "884/884 [==============================] - 0s 42us/sample - loss: 0.0233 - accuracy: 0.9977\n",
      "Epoch 66/100\n",
      "884/884 [==============================] - 0s 41us/sample - loss: 0.0234 - accuracy: 0.9977\n",
      "Epoch 67/100\n",
      "884/884 [==============================] - 0s 26us/sample - loss: 0.0231 - accuracy: 0.9977\n",
      "Epoch 68/100\n",
      "884/884 [==============================] - 0s 23us/sample - loss: 0.0231 - accuracy: 0.9977\n",
      "Epoch 69/100\n",
      "884/884 [==============================] - 0s 26us/sample - loss: 0.0225 - accuracy: 0.9977\n",
      "Epoch 70/100\n",
      "884/884 [==============================] - 0s 21us/sample - loss: 0.0221 - accuracy: 0.9977\n",
      "Epoch 71/100\n",
      "884/884 [==============================] - 0s 27us/sample - loss: 0.0217 - accuracy: 0.9977\n",
      "Epoch 72/100\n",
      "884/884 [==============================] - 0s 25us/sample - loss: 0.0214 - accuracy: 0.9977\n",
      "Epoch 73/100\n",
      "884/884 [==============================] - 0s 27us/sample - loss: 0.0210 - accuracy: 0.9977\n",
      "Epoch 74/100\n",
      "884/884 [==============================] - 0s 28us/sample - loss: 0.0208 - accuracy: 0.9977\n",
      "Epoch 75/100\n",
      "884/884 [==============================] - 0s 24us/sample - loss: 0.0205 - accuracy: 0.9977\n",
      "Epoch 76/100\n",
      "884/884 [==============================] - 0s 27us/sample - loss: 0.0212 - accuracy: 0.9966\n",
      "Epoch 77/100\n",
      "884/884 [==============================] - 0s 25us/sample - loss: 0.0207 - accuracy: 0.9977\n",
      "Epoch 78/100\n",
      "884/884 [==============================] - 0s 25us/sample - loss: 0.0213 - accuracy: 0.9977\n",
      "Epoch 79/100\n",
      "884/884 [==============================] - 0s 28us/sample - loss: 0.0207 - accuracy: 0.9977\n",
      "Epoch 80/100\n",
      "884/884 [==============================] - 0s 28us/sample - loss: 0.0200 - accuracy: 0.9977\n",
      "Epoch 81/100\n",
      "884/884 [==============================] - 0s 29us/sample - loss: 0.0192 - accuracy: 0.9977\n",
      "Epoch 82/100\n",
      "884/884 [==============================] - 0s 26us/sample - loss: 0.0190 - accuracy: 0.9977\n",
      "Epoch 83/100\n",
      "884/884 [==============================] - 0s 27us/sample - loss: 0.0187 - accuracy: 0.9977\n",
      "Epoch 84/100\n",
      "884/884 [==============================] - 0s 24us/sample - loss: 0.0183 - accuracy: 0.9977\n",
      "Epoch 85/100\n",
      "884/884 [==============================] - 0s 26us/sample - loss: 0.0186 - accuracy: 0.9989\n",
      "Epoch 86/100\n",
      "884/884 [==============================] - 0s 26us/sample - loss: 0.0183 - accuracy: 0.9977\n",
      "Epoch 87/100\n",
      "884/884 [==============================] - 0s 25us/sample - loss: 0.0181 - accuracy: 0.9977\n",
      "Epoch 88/100\n",
      "884/884 [==============================] - 0s 24us/sample - loss: 0.0175 - accuracy: 0.9989\n",
      "Epoch 89/100\n",
      "884/884 [==============================] - 0s 26us/sample - loss: 0.0176 - accuracy: 0.9989\n",
      "Epoch 90/100\n",
      "884/884 [==============================] - 0s 24us/sample - loss: 0.0173 - accuracy: 0.9989\n",
      "Epoch 91/100\n",
      "884/884 [==============================] - 0s 43us/sample - loss: 0.0170 - accuracy: 0.9989\n",
      "Epoch 92/100\n",
      "884/884 [==============================] - 0s 23us/sample - loss: 0.0165 - accuracy: 0.9989\n",
      "Epoch 93/100\n",
      "884/884 [==============================] - 0s 28us/sample - loss: 0.0171 - accuracy: 0.9989\n",
      "Epoch 94/100\n",
      "884/884 [==============================] - 0s 25us/sample - loss: 0.0167 - accuracy: 0.9989\n",
      "Epoch 95/100\n",
      "884/884 [==============================] - 0s 27us/sample - loss: 0.0164 - accuracy: 0.9989\n",
      "Epoch 96/100\n",
      "884/884 [==============================] - 0s 36us/sample - loss: 0.0159 - accuracy: 0.9989\n",
      "Epoch 97/100\n",
      "884/884 [==============================] - 0s 30us/sample - loss: 0.0156 - accuracy: 0.9989\n",
      "Epoch 98/100\n",
      "884/884 [==============================] - 0s 28us/sample - loss: 0.0160 - accuracy: 0.9989\n",
      "Epoch 99/100\n",
      "884/884 [==============================] - 0s 29us/sample - loss: 0.0157 - accuracy: 0.9989\n",
      "Epoch 100/100\n",
      "884/884 [==============================] - 0s 24us/sample - loss: 0.0154 - accuracy: 0.9989\n",
      "Completed Model 1\n",
      "Train on 884 samples\n",
      "Epoch 1/100\n",
      "884/884 [==============================] - 0s 41us/sample - loss: 0.0435 - accuracy: 0.9864\n",
      "Epoch 2/100\n",
      "884/884 [==============================] - 0s 33us/sample - loss: 0.0550 - accuracy: 0.9864\n",
      "Epoch 3/100\n",
      "884/884 [==============================] - 0s 32us/sample - loss: 0.0528 - accuracy: 0.9853\n",
      "Epoch 4/100\n",
      "884/884 [==============================] - 0s 25us/sample - loss: 0.0422 - accuracy: 0.9887\n",
      "Epoch 5/100\n",
      "884/884 [==============================] - 0s 36us/sample - loss: 0.0441 - accuracy: 0.9921\n",
      "Epoch 6/100\n",
      "884/884 [==============================] - 0s 32us/sample - loss: 0.0481 - accuracy: 0.9864\n",
      "Epoch 7/100\n",
      "884/884 [==============================] - 0s 41us/sample - loss: 0.0472 - accuracy: 0.9876\n",
      "Epoch 8/100\n",
      "884/884 [==============================] - 0s 35us/sample - loss: 0.0365 - accuracy: 0.9921\n",
      "Epoch 9/100\n",
      "884/884 [==============================] - 0s 35us/sample - loss: 0.0388 - accuracy: 0.9932\n",
      "Epoch 10/100\n",
      "884/884 [==============================] - 0s 25us/sample - loss: 0.0305 - accuracy: 0.9943\n",
      "Epoch 11/100\n",
      "884/884 [==============================] - 0s 24us/sample - loss: 0.0284 - accuracy: 0.9943\n",
      "Epoch 12/100\n",
      "884/884 [==============================] - 0s 23us/sample - loss: 0.0353 - accuracy: 0.9943\n",
      "Epoch 13/100\n",
      "884/884 [==============================] - 0s 24us/sample - loss: 0.0296 - accuracy: 0.9943\n",
      "Epoch 14/100\n",
      "884/884 [==============================] - 0s 25us/sample - loss: 0.0261 - accuracy: 0.9955\n",
      "Epoch 15/100\n",
      "884/884 [==============================] - 0s 26us/sample - loss: 0.0268 - accuracy: 0.9943\n",
      "Epoch 16/100\n",
      "884/884 [==============================] - 0s 25us/sample - loss: 0.0285 - accuracy: 0.9955\n",
      "Epoch 17/100\n",
      "884/884 [==============================] - 0s 26us/sample - loss: 0.0264 - accuracy: 0.9955\n",
      "Epoch 18/100\n",
      "884/884 [==============================] - 0s 27us/sample - loss: 0.0240 - accuracy: 0.9955\n",
      "Epoch 19/100\n",
      "884/884 [==============================] - 0s 29us/sample - loss: 0.0233 - accuracy: 0.9966\n",
      "Epoch 20/100\n",
      "884/884 [==============================] - 0s 32us/sample - loss: 0.0275 - accuracy: 0.9966\n",
      "Epoch 21/100\n",
      "884/884 [==============================] - 0s 25us/sample - loss: 0.0241 - accuracy: 0.9955\n",
      "Epoch 22/100\n",
      "884/884 [==============================] - 0s 25us/sample - loss: 0.0238 - accuracy: 0.9966\n",
      "Epoch 23/100\n",
      "884/884 [==============================] - 0s 24us/sample - loss: 0.0226 - accuracy: 0.9966\n",
      "Epoch 24/100\n",
      "884/884 [==============================] - 0s 25us/sample - loss: 0.0227 - accuracy: 0.9966\n",
      "Epoch 25/100\n",
      "884/884 [==============================] - 0s 26us/sample - loss: 0.0199 - accuracy: 0.9989\n",
      "Epoch 26/100\n",
      "884/884 [==============================] - 0s 29us/sample - loss: 0.0264 - accuracy: 0.9977\n",
      "Epoch 27/100\n",
      "884/884 [==============================] - 0s 27us/sample - loss: 0.0408 - accuracy: 0.9921\n",
      "Epoch 28/100\n",
      "884/884 [==============================] - 0s 26us/sample - loss: 0.0362 - accuracy: 0.9932\n",
      "Epoch 29/100\n",
      "884/884 [==============================] - 0s 29us/sample - loss: 0.0268 - accuracy: 0.9966\n",
      "Epoch 30/100\n",
      "884/884 [==============================] - 0s 23us/sample - loss: 0.0200 - accuracy: 0.9989\n",
      "Epoch 31/100\n",
      "884/884 [==============================] - 0s 26us/sample - loss: 0.0181 - accuracy: 0.9977\n",
      "Epoch 32/100\n",
      "884/884 [==============================] - 0s 24us/sample - loss: 0.0185 - accuracy: 0.9989\n",
      "Epoch 33/100\n",
      "884/884 [==============================] - 0s 24us/sample - loss: 0.0167 - accuracy: 0.9989\n",
      "Epoch 34/100\n",
      "884/884 [==============================] - 0s 25us/sample - loss: 0.0181 - accuracy: 0.9989\n",
      "Epoch 35/100\n",
      "884/884 [==============================] - 0s 24us/sample - loss: 0.0216 - accuracy: 0.9989\n",
      "Epoch 36/100\n",
      "884/884 [==============================] - 0s 27us/sample - loss: 0.0233 - accuracy: 0.9989\n",
      "Epoch 37/100\n",
      "884/884 [==============================] - 0s 24us/sample - loss: 0.0194 - accuracy: 0.9989\n",
      "Epoch 38/100\n",
      "884/884 [==============================] - 0s 26us/sample - loss: 0.0153 - accuracy: 0.9989\n",
      "Epoch 39/100\n",
      "884/884 [==============================] - 0s 26us/sample - loss: 0.0135 - accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "884/884 [==============================] - 0s 25us/sample - loss: 0.0172 - accuracy: 0.9989\n",
      "Epoch 41/100\n",
      "884/884 [==============================] - 0s 24us/sample - loss: 0.0181 - accuracy: 0.9989\n",
      "Epoch 42/100\n",
      "884/884 [==============================] - 0s 28us/sample - loss: 0.0174 - accuracy: 0.9989\n",
      "Epoch 43/100\n",
      "884/884 [==============================] - 0s 26us/sample - loss: 0.0146 - accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "884/884 [==============================] - 0s 36us/sample - loss: 0.0156 - accuracy: 0.9989\n",
      "Epoch 45/100\n",
      "884/884 [==============================] - 0s 24us/sample - loss: 0.0159 - accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "884/884 [==============================] - 0s 24us/sample - loss: 0.0162 - accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "884/884 [==============================] - 0s 63us/sample - loss: 0.0139 - accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "884/884 [==============================] - 0s 50us/sample - loss: 0.0117 - accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "884/884 [==============================] - 0s 54us/sample - loss: 0.0115 - accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "884/884 [==============================] - 0s 37us/sample - loss: 0.0113 - accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "884/884 [==============================] - 0s 38us/sample - loss: 0.0134 - accuracy: 0.9989\n",
      "Epoch 52/100\n",
      "884/884 [==============================] - 0s 35us/sample - loss: 0.0143 - accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "884/884 [==============================] - 0s 29us/sample - loss: 0.0129 - accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "884/884 [==============================] - 0s 32us/sample - loss: 0.0109 - accuracy: 1.0000\n",
      "Epoch 55/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "884/884 [==============================] - 0s 37us/sample - loss: 0.0109 - accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "884/884 [==============================] - 0s 51us/sample - loss: 0.0118 - accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "884/884 [==============================] - 0s 25us/sample - loss: 0.0107 - accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "884/884 [==============================] - 0s 25us/sample - loss: 0.0120 - accuracy: 0.9989\n",
      "Epoch 59/100\n",
      "884/884 [==============================] - 0s 24us/sample - loss: 0.0133 - accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "884/884 [==============================] - 0s 24us/sample - loss: 0.0128 - accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "884/884 [==============================] - 0s 25us/sample - loss: 0.0108 - accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "884/884 [==============================] - 0s 44us/sample - loss: 0.0092 - accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "884/884 [==============================] - 0s 29us/sample - loss: 0.0097 - accuracy: 0.9989\n",
      "Epoch 64/100\n",
      "884/884 [==============================] - 0s 28us/sample - loss: 0.0110 - accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "884/884 [==============================] - 0s 34us/sample - loss: 0.0113 - accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "884/884 [==============================] - 0s 46us/sample - loss: 0.0099 - accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "884/884 [==============================] - 0s 54us/sample - loss: 0.0093 - accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "884/884 [==============================] - 0s 63us/sample - loss: 0.0094 - accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "884/884 [==============================] - 0s 24us/sample - loss: 0.0087 - accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "884/884 [==============================] - 0s 27us/sample - loss: 0.0085 - accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "884/884 [==============================] - 0s 26us/sample - loss: 0.0085 - accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "884/884 [==============================] - 0s 27us/sample - loss: 0.0083 - accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "884/884 [==============================] - 0s 25us/sample - loss: 0.0084 - accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "884/884 [==============================] - 0s 26us/sample - loss: 0.0081 - accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "884/884 [==============================] - 0s 24us/sample - loss: 0.0089 - accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "884/884 [==============================] - 0s 27us/sample - loss: 0.0095 - accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "884/884 [==============================] - 0s 29us/sample - loss: 0.0088 - accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "884/884 [==============================] - 0s 25us/sample - loss: 0.0076 - accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "884/884 [==============================] - 0s 56us/sample - loss: 0.0096 - accuracy: 0.9989\n",
      "Epoch 80/100\n",
      "884/884 [==============================] - 0s 34us/sample - loss: 0.0099 - accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "884/884 [==============================] - 0s 27us/sample - loss: 0.0089 - accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "884/884 [==============================] - 0s 27us/sample - loss: 0.0076 - accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "884/884 [==============================] - 0s 25us/sample - loss: 0.0093 - accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "884/884 [==============================] - 0s 25us/sample - loss: 0.0165 - accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "884/884 [==============================] - 0s 24us/sample - loss: 0.0167 - accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "884/884 [==============================] - 0s 27us/sample - loss: 0.0131 - accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "884/884 [==============================] - 0s 33us/sample - loss: 0.0100 - accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "884/884 [==============================] - 0s 25us/sample - loss: 0.0081 - accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "884/884 [==============================] - 0s 29us/sample - loss: 0.0069 - accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "884/884 [==============================] - 0s 43us/sample - loss: 0.0072 - accuracy: 0.9989\n",
      "Epoch 91/100\n",
      "884/884 [==============================] - 0s 26us/sample - loss: 0.0085 - accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "884/884 [==============================] - 0s 25us/sample - loss: 0.0090 - accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "884/884 [==============================] - 0s 25us/sample - loss: 0.0079 - accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "884/884 [==============================] - 0s 28us/sample - loss: 0.0068 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "884/884 [==============================] - 0s 46us/sample - loss: 0.0060 - accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "884/884 [==============================] - 0s 33us/sample - loss: 0.0061 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "884/884 [==============================] - 0s 29us/sample - loss: 0.0060 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "884/884 [==============================] - 0s 26us/sample - loss: 0.0065 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "884/884 [==============================] - 0s 27us/sample - loss: 0.0072 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "884/884 [==============================] - 0s 24us/sample - loss: 0.0068 - accuracy: 1.0000\n",
      "Completed Model 2\n",
      "Train on 884 samples\n",
      "Epoch 1/100\n",
      "884/884 [==============================] - 0s 29us/sample - loss: 0.0079 - accuracy: 1.0000\n",
      "Epoch 2/100\n",
      "884/884 [==============================] - 0s 25us/sample - loss: 0.0106 - accuracy: 1.0000\n",
      "Epoch 3/100\n",
      "884/884 [==============================] - 0s 24us/sample - loss: 0.0141 - accuracy: 1.0000\n",
      "Epoch 4/100\n",
      "884/884 [==============================] - 0s 24us/sample - loss: 0.0090 - accuracy: 1.0000\n",
      "Epoch 5/100\n",
      "884/884 [==============================] - 0s 25us/sample - loss: 0.0069 - accuracy: 1.0000\n",
      "Epoch 6/100\n",
      "884/884 [==============================] - 0s 24us/sample - loss: 0.0094 - accuracy: 1.0000\n",
      "Epoch 7/100\n",
      "884/884 [==============================] - 0s 29us/sample - loss: 0.0075 - accuracy: 1.0000\n",
      "Epoch 8/100\n",
      "884/884 [==============================] - 0s 24us/sample - loss: 0.0058 - accuracy: 1.0000\n",
      "Epoch 9/100\n",
      "884/884 [==============================] - 0s 26us/sample - loss: 0.0089 - accuracy: 1.0000\n",
      "Epoch 10/100\n",
      "884/884 [==============================] - 0s 28us/sample - loss: 0.0099 - accuracy: 1.0000\n",
      "Epoch 11/100\n",
      "884/884 [==============================] - 0s 28us/sample - loss: 0.0069 - accuracy: 1.0000\n",
      "Epoch 12/100\n",
      "884/884 [==============================] - 0s 41us/sample - loss: 0.0064 - accuracy: 0.9989\n",
      "Epoch 13/100\n",
      "884/884 [==============================] - 0s 36us/sample - loss: 0.0104 - accuracy: 1.0000\n",
      "Epoch 14/100\n",
      "884/884 [==============================] - 0s 32us/sample - loss: 0.0088 - accuracy: 1.0000\n",
      "Epoch 15/100\n",
      "884/884 [==============================] - 0s 28us/sample - loss: 0.0058 - accuracy: 1.0000\n",
      "Epoch 16/100\n",
      "884/884 [==============================] - 0s 25us/sample - loss: 0.0060 - accuracy: 1.0000\n",
      "Epoch 17/100\n",
      "884/884 [==============================] - 0s 28us/sample - loss: 0.0057 - accuracy: 1.0000\n",
      "Epoch 18/100\n",
      "884/884 [==============================] - 0s 28us/sample - loss: 0.0071 - accuracy: 0.9989\n",
      "Epoch 19/100\n",
      "884/884 [==============================] - 0s 28us/sample - loss: 0.0128 - accuracy: 1.0000\n",
      "Epoch 20/100\n",
      "884/884 [==============================] - 0s 27us/sample - loss: 0.0094 - accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "884/884 [==============================] - 0s 26us/sample - loss: 0.0055 - accuracy: 1.0000\n",
      "Epoch 22/100\n",
      "884/884 [==============================] - 0s 28us/sample - loss: 0.0131 - accuracy: 1.0000\n",
      "Epoch 23/100\n",
      "884/884 [==============================] - 0s 26us/sample - loss: 0.0486 - accuracy: 0.9943\n",
      "Epoch 24/100\n",
      "884/884 [==============================] - 0s 23us/sample - loss: 0.0155 - accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "884/884 [==============================] - 0s 25us/sample - loss: 0.0052 - accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "884/884 [==============================] - 0s 25us/sample - loss: 0.0050 - accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "884/884 [==============================] - 0s 24us/sample - loss: 0.0056 - accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "884/884 [==============================] - 0s 26us/sample - loss: 0.0045 - accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "884/884 [==============================] - 0s 26us/sample - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "884/884 [==============================] - 0s 24us/sample - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "884/884 [==============================] - 0s 24us/sample - loss: 0.0039 - accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "884/884 [==============================] - 0s 49us/sample - loss: 0.0040 - accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "884/884 [==============================] - 0s 32us/sample - loss: 0.0040 - accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "884/884 [==============================] - 0s 24us/sample - loss: 0.0047 - accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "884/884 [==============================] - 0s 25us/sample - loss: 0.0041 - accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "884/884 [==============================] - 0s 26us/sample - loss: 0.0050 - accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "884/884 [==============================] - 0s 25us/sample - loss: 0.0085 - accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "884/884 [==============================] - 0s 25us/sample - loss: 0.0069 - accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "884/884 [==============================] - 0s 27us/sample - loss: 0.0045 - accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "884/884 [==============================] - 0s 30us/sample - loss: 0.0035 - accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "884/884 [==============================] - 0s 29us/sample - loss: 0.0039 - accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "884/884 [==============================] - 0s 25us/sample - loss: 0.0039 - accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "884/884 [==============================] - 0s 27us/sample - loss: 0.0039 - accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "884/884 [==============================] - 0s 23us/sample - loss: 0.0081 - accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "884/884 [==============================] - 0s 39us/sample - loss: 0.0102 - accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "884/884 [==============================] - 0s 35us/sample - loss: 0.0061 - accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "884/884 [==============================] - 0s 24us/sample - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "884/884 [==============================] - 0s 29us/sample - loss: 0.0035 - accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "884/884 [==============================] - 0s 26us/sample - loss: 0.0060 - accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "884/884 [==============================] - 0s 28us/sample - loss: 0.0067 - accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "884/884 [==============================] - 0s 26us/sample - loss: 0.0047 - accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "884/884 [==============================] - 0s 25us/sample - loss: 0.0032 - accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "884/884 [==============================] - 0s 25us/sample - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "884/884 [==============================] - 0s 60us/sample - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "884/884 [==============================] - 0s 46us/sample - loss: 0.0034 - accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "884/884 [==============================] - 0s 29us/sample - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "884/884 [==============================] - 0s 27us/sample - loss: 0.0057 - accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "884/884 [==============================] - 0s 34us/sample - loss: 0.0080 - accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "884/884 [==============================] - 0s 23us/sample - loss: 0.0057 - accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "884/884 [==============================] - 0s 24us/sample - loss: 0.0036 - accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "884/884 [==============================] - 0s 25us/sample - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "884/884 [==============================] - 0s 27us/sample - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "884/884 [==============================] - 0s 25us/sample - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "884/884 [==============================] - 0s 24us/sample - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "884/884 [==============================] - 0s 25us/sample - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "884/884 [==============================] - 0s 25us/sample - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "884/884 [==============================] - 0s 24us/sample - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "884/884 [==============================] - 0s 25us/sample - loss: 0.0030 - accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "884/884 [==============================] - 0s 29us/sample - loss: 0.0030 - accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "884/884 [==============================] - 0s 115us/sample - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "884/884 [==============================] - 0s 47us/sample - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "884/884 [==============================] - 0s 26us/sample - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "884/884 [==============================] - 0s 72us/sample - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "884/884 [==============================] - 0s 39us/sample - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "884/884 [==============================] - 0s 28us/sample - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "884/884 [==============================] - 0s 27us/sample - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "884/884 [==============================] - 0s 23us/sample - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "884/884 [==============================] - 0s 24us/sample - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "884/884 [==============================] - 0s 25us/sample - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "884/884 [==============================] - 0s 23us/sample - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "884/884 [==============================] - 0s 27us/sample - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "884/884 [==============================] - 0s 32us/sample - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "884/884 [==============================] - 0s 25us/sample - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "884/884 [==============================] - 0s 24us/sample - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "884/884 [==============================] - 0s 25us/sample - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "884/884 [==============================] - 0s 23us/sample - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "884/884 [==============================] - 0s 26us/sample - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "884/884 [==============================] - 0s 32us/sample - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "884/884 [==============================] - 0s 34us/sample - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "884/884 [==============================] - 0s 36us/sample - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "884/884 [==============================] - 0s 34us/sample - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "884/884 [==============================] - 0s 30us/sample - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "884/884 [==============================] - 0s 33us/sample - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "884/884 [==============================] - 0s 29us/sample - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "884/884 [==============================] - 0s 27us/sample - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "884/884 [==============================] - 0s 29us/sample - loss: 0.0048 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "884/884 [==============================] - 0s 29us/sample - loss: 0.0062 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "884/884 [==============================] - 0s 26us/sample - loss: 0.0043 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "884/884 [==============================] - 0s 26us/sample - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "884/884 [==============================] - 0s 24us/sample - loss: 0.0019 - accuracy: 1.0000\n",
      "Completed Model 3\n",
      "Train on 884 samples\n",
      "Epoch 1/100\n",
      "884/884 [==============================] - 0s 32us/sample - loss: 0.0041 - accuracy: 1.0000\n",
      "Epoch 2/100\n",
      "884/884 [==============================] - 0s 24us/sample - loss: 0.0043 - accuracy: 1.0000\n",
      "Epoch 3/100\n",
      "884/884 [==============================] - 0s 25us/sample - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 4/100\n",
      "884/884 [==============================] - 0s 26us/sample - loss: 0.0046 - accuracy: 1.0000\n",
      "Epoch 5/100\n",
      "884/884 [==============================] - 0s 28us/sample - loss: 0.0040 - accuracy: 1.0000\n",
      "Epoch 6/100\n",
      "884/884 [==============================] - 0s 26us/sample - loss: 0.0036 - accuracy: 1.0000\n",
      "Epoch 7/100\n",
      "884/884 [==============================] - 0s 36us/sample - loss: 0.0037 - accuracy: 1.0000\n",
      "Epoch 8/100\n",
      "884/884 [==============================] - 0s 47us/sample - loss: 0.0037 - accuracy: 1.0000\n",
      "Epoch 9/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "884/884 [==============================] - 0s 55us/sample - loss: 0.0050 - accuracy: 1.0000\n",
      "Epoch 10/100\n",
      "884/884 [==============================] - 0s 33us/sample - loss: 0.0046 - accuracy: 1.0000\n",
      "Epoch 11/100\n",
      "884/884 [==============================] - 0s 37us/sample - loss: 0.0066 - accuracy: 1.0000\n",
      "Epoch 12/100\n",
      "884/884 [==============================] - 0s 33us/sample - loss: 0.0048 - accuracy: 1.0000\n",
      "Epoch 13/100\n",
      "884/884 [==============================] - 0s 30us/sample - loss: 0.0032 - accuracy: 1.0000\n",
      "Epoch 14/100\n",
      "884/884 [==============================] - 0s 27us/sample - loss: 0.0035 - accuracy: 1.0000\n",
      "Epoch 15/100\n",
      "884/884 [==============================] - 0s 28us/sample - loss: 0.0039 - accuracy: 1.0000\n",
      "Epoch 16/100\n",
      "884/884 [==============================] - 0s 29us/sample - loss: 0.0228 - accuracy: 0.9989\n",
      "Epoch 17/100\n",
      "884/884 [==============================] - 0s 26us/sample - loss: 0.0058 - accuracy: 1.0000\n",
      "Epoch 18/100\n",
      "884/884 [==============================] - 0s 24us/sample - loss: 0.0185 - accuracy: 0.9989\n",
      "Epoch 19/100\n",
      "884/884 [==============================] - 0s 27us/sample - loss: 0.0054 - accuracy: 1.0000\n",
      "Epoch 20/100\n",
      "884/884 [==============================] - 0s 24us/sample - loss: 0.0068 - accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "884/884 [==============================] - 0s 29us/sample - loss: 0.0061 - accuracy: 1.0000\n",
      "Epoch 22/100\n",
      "884/884 [==============================] - 0s 36us/sample - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 23/100\n",
      "884/884 [==============================] - 0s 35us/sample - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 24/100\n",
      "884/884 [==============================] - 0s 26us/sample - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "884/884 [==============================] - 0s 25us/sample - loss: 0.0645 - accuracy: 0.9842\n",
      "Epoch 26/100\n",
      "884/884 [==============================] - 0s 32us/sample - loss: 0.0185 - accuracy: 0.9977\n",
      "Epoch 27/100\n",
      "884/884 [==============================] - 0s 25us/sample - loss: 0.0478 - accuracy: 0.9898\n",
      "Epoch 28/100\n",
      "884/884 [==============================] - 0s 25us/sample - loss: 0.1955 - accuracy: 0.9061\n",
      "Epoch 29/100\n",
      "884/884 [==============================] - 0s 23us/sample - loss: 0.1590 - accuracy: 0.9287\n",
      "Epoch 30/100\n",
      "884/884 [==============================] - 0s 28us/sample - loss: 0.0070 - accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "884/884 [==============================] - 0s 38us/sample - loss: 0.0159 - accuracy: 0.9977\n",
      "Epoch 32/100\n",
      "884/884 [==============================] - 0s 34us/sample - loss: 0.0056 - accuracy: 0.9989\n",
      "Epoch 33/100\n",
      "884/884 [==============================] - 0s 30us/sample - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "884/884 [==============================] - 0s 25us/sample - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "884/884 [==============================] - 0s 28us/sample - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "884/884 [==============================] - 0s 27us/sample - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "884/884 [==============================] - 0s 26us/sample - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "884/884 [==============================] - 0s 38us/sample - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "884/884 [==============================] - 0s 27us/sample - loss: 9.4570e-04 - accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "884/884 [==============================] - 0s 27us/sample - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "884/884 [==============================] - 0s 26us/sample - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "884/884 [==============================] - 0s 27us/sample - loss: 8.9077e-04 - accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "884/884 [==============================] - 0s 25us/sample - loss: 8.6945e-04 - accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "884/884 [==============================] - 0s 26us/sample - loss: 8.5007e-04 - accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "884/884 [==============================] - 0s 25us/sample - loss: 8.6721e-04 - accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "884/884 [==============================] - 0s 26us/sample - loss: 8.5330e-04 - accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "884/884 [==============================] - 0s 29us/sample - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "884/884 [==============================] - 0s 58us/sample - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "884/884 [==============================] - 0s 59us/sample - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "884/884 [==============================] - 0s 90us/sample - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "884/884 [==============================] - 0s 49us/sample - loss: 8.2741e-04 - accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "884/884 [==============================] - 0s 33us/sample - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "884/884 [==============================] - 0s 46us/sample - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "884/884 [==============================] - 0s 47us/sample - loss: 9.3806e-04 - accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "884/884 [==============================] - 0s 34us/sample - loss: 9.9148e-04 - accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "884/884 [==============================] - 0s 44us/sample - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "884/884 [==============================] - 0s 49us/sample - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "884/884 [==============================] - 0s 37us/sample - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "884/884 [==============================] - 0s 41us/sample - loss: 8.7036e-04 - accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "884/884 [==============================] - 0s 43us/sample - loss: 8.1298e-04 - accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "884/884 [==============================] - 0s 85us/sample - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "884/884 [==============================] - 0s 53us/sample - loss: 9.4949e-04 - accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "884/884 [==============================] - 0s 45us/sample - loss: 7.8860e-04 - accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "884/884 [==============================] - 0s 71us/sample - loss: 7.8416e-04 - accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "884/884 [==============================] - 0s 39us/sample - loss: 7.4542e-04 - accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "884/884 [==============================] - 0s 56us/sample - loss: 7.2758e-04 - accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "884/884 [==============================] - 0s 73us/sample - loss: 7.5813e-04 - accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "884/884 [==============================] - 0s 39us/sample - loss: 8.3442e-04 - accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "884/884 [==============================] - 0s 43us/sample - loss: 7.9120e-04 - accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "884/884 [==============================] - 0s 38us/sample - loss: 7.6380e-04 - accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "884/884 [==============================] - 0s 43us/sample - loss: 8.3801e-04 - accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "884/884 [==============================] - 0s 53us/sample - loss: 7.9374e-04 - accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "884/884 [==============================] - 0s 41us/sample - loss: 7.6220e-04 - accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "884/884 [==============================] - 0s 49us/sample - loss: 8.7735e-04 - accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "884/884 [==============================] - 0s 53us/sample - loss: 7.9085e-04 - accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "884/884 [==============================] - 0s 37us/sample - loss: 7.0177e-04 - accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "884/884 [==============================] - 0s 29us/sample - loss: 7.0191e-04 - accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "884/884 [==============================] - 0s 29us/sample - loss: 6.9342e-04 - accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "884/884 [==============================] - 0s 24us/sample - loss: 6.8818e-04 - accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "884/884 [==============================] - 0s 27us/sample - loss: 6.9233e-04 - accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "884/884 [==============================] - 0s 26us/sample - loss: 6.8752e-04 - accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "884/884 [==============================] - 0s 24us/sample - loss: 6.7541e-04 - accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "884/884 [==============================] - 0s 26us/sample - loss: 7.1731e-04 - accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "884/884 [==============================] - 0s 24us/sample - loss: 8.0482e-04 - accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "884/884 [==============================] - 0s 25us/sample - loss: 7.4396e-04 - accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "884/884 [==============================] - 0s 24us/sample - loss: 6.6812e-04 - accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "884/884 [==============================] - 0s 27us/sample - loss: 6.8092e-04 - accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "884/884 [==============================] - 0s 27us/sample - loss: 7.8118e-04 - accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "884/884 [==============================] - 0s 30us/sample - loss: 7.3809e-04 - accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "884/884 [==============================] - 0s 28us/sample - loss: 6.5463e-04 - accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "884/884 [==============================] - 0s 30us/sample - loss: 6.6431e-04 - accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "884/884 [==============================] - 0s 27us/sample - loss: 6.6909e-04 - accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "884/884 [==============================] - 0s 29us/sample - loss: 6.5688e-04 - accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "884/884 [==============================] - 0s 29us/sample - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "884/884 [==============================] - 0s 27us/sample - loss: 0.0032 - accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "884/884 [==============================] - 0s 27us/sample - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "884/884 [==============================] - 0s 30us/sample - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "884/884 [==============================] - 0s 30us/sample - loss: 6.8159e-04 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "884/884 [==============================] - 0s 34us/sample - loss: 6.4681e-04 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "884/884 [==============================] - 0s 29us/sample - loss: 8.6095e-04 - accuracy: 1.0000\n",
      "Completed Model 4\n",
      "Train on 884 samples\n",
      "Epoch 1/100\n",
      "884/884 [==============================] - 0s 42us/sample - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 2/100\n",
      "884/884 [==============================] - 0s 36us/sample - loss: 0.0033 - accuracy: 1.0000\n",
      "Epoch 3/100\n",
      "884/884 [==============================] - 0s 35us/sample - loss: 0.0047 - accuracy: 1.0000\n",
      "Epoch 4/100\n",
      "884/884 [==============================] - 0s 34us/sample - loss: 0.0033 - accuracy: 1.0000\n",
      "Epoch 5/100\n",
      "884/884 [==============================] - 0s 27us/sample - loss: 0.0132 - accuracy: 0.9989\n",
      "Epoch 6/100\n",
      "884/884 [==============================] - 0s 33us/sample - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 7/100\n",
      "884/884 [==============================] - 0s 28us/sample - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 8/100\n",
      "884/884 [==============================] - 0s 34us/sample - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 9/100\n",
      "884/884 [==============================] - 0s 30us/sample - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 10/100\n",
      "884/884 [==============================] - 0s 33us/sample - loss: 9.8529e-04 - accuracy: 1.0000\n",
      "Epoch 11/100\n",
      "884/884 [==============================] - 0s 33us/sample - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 12/100\n",
      "884/884 [==============================] - 0s 28us/sample - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 13/100\n",
      "884/884 [==============================] - 0s 29us/sample - loss: 8.8548e-04 - accuracy: 1.0000\n",
      "Epoch 14/100\n",
      "884/884 [==============================] - 0s 32us/sample - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 15/100\n",
      "884/884 [==============================] - 0s 34us/sample - loss: 8.3049e-04 - accuracy: 1.0000\n",
      "Epoch 16/100\n",
      "884/884 [==============================] - 0s 37us/sample - loss: 8.2959e-04 - accuracy: 1.0000\n",
      "Epoch 17/100\n",
      "884/884 [==============================] - 0s 42us/sample - loss: 7.7741e-04 - accuracy: 1.0000\n",
      "Epoch 18/100\n",
      "884/884 [==============================] - 0s 35us/sample - loss: 7.6873e-04 - accuracy: 1.0000\n",
      "Epoch 19/100\n",
      "884/884 [==============================] - 0s 28us/sample - loss: 7.9759e-04 - accuracy: 1.0000\n",
      "Epoch 20/100\n",
      "884/884 [==============================] - 0s 33us/sample - loss: 7.7815e-04 - accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "884/884 [==============================] - 0s 35us/sample - loss: 7.5609e-04 - accuracy: 1.0000\n",
      "Epoch 22/100\n",
      "884/884 [==============================] - 0s 29us/sample - loss: 7.6539e-04 - accuracy: 1.0000\n",
      "Epoch 23/100\n",
      "884/884 [==============================] - 0s 25us/sample - loss: 7.3140e-04 - accuracy: 1.0000\n",
      "Epoch 24/100\n",
      "884/884 [==============================] - 0s 23us/sample - loss: 7.3833e-04 - accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "884/884 [==============================] - 0s 24us/sample - loss: 7.4883e-04 - accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "884/884 [==============================] - 0s 24us/sample - loss: 7.8256e-04 - accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "884/884 [==============================] - 0s 23us/sample - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "884/884 [==============================] - 0s 25us/sample - loss: 0.0063 - accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "884/884 [==============================] - 0s 24us/sample - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "884/884 [==============================] - 0s 24us/sample - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "884/884 [==============================] - 0s 25us/sample - loss: 8.7618e-04 - accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "884/884 [==============================] - 0s 24us/sample - loss: 8.7904e-04 - accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "884/884 [==============================] - 0s 26us/sample - loss: 9.9526e-04 - accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "884/884 [==============================] - 0s 26us/sample - loss: 7.0121e-04 - accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "884/884 [==============================] - 0s 26us/sample - loss: 7.4279e-04 - accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "884/884 [==============================] - 0s 26us/sample - loss: 6.9047e-04 - accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "884/884 [==============================] - 0s 28us/sample - loss: 6.9505e-04 - accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "884/884 [==============================] - 0s 37us/sample - loss: 6.6061e-04 - accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "884/884 [==============================] - 0s 32us/sample - loss: 6.6181e-04 - accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "884/884 [==============================] - 0s 25us/sample - loss: 7.0324e-04 - accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "884/884 [==============================] - 0s 28us/sample - loss: 7.5460e-04 - accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "884/884 [==============================] - 0s 26us/sample - loss: 6.6216e-04 - accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "884/884 [==============================] - 0s 24us/sample - loss: 6.3654e-04 - accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "884/884 [==============================] - 0s 26us/sample - loss: 7.0206e-04 - accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "884/884 [==============================] - 0s 25us/sample - loss: 6.6894e-04 - accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "884/884 [==============================] - 0s 26us/sample - loss: 7.0565e-04 - accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "884/884 [==============================] - 0s 27us/sample - loss: 7.0022e-04 - accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "884/884 [==============================] - 0s 25us/sample - loss: 8.8562e-04 - accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "884/884 [==============================] - 0s 26us/sample - loss: 7.0069e-04 - accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "884/884 [==============================] - 0s 41us/sample - loss: 7.4934e-04 - accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "884/884 [==============================] - 0s 39us/sample - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "884/884 [==============================] - 0s 24us/sample - loss: 7.9093e-04 - accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "884/884 [==============================] - 0s 28us/sample - loss: 7.8791e-04 - accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "884/884 [==============================] - 0s 28us/sample - loss: 6.5878e-04 - accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "884/884 [==============================] - 0s 28us/sample - loss: 7.5500e-04 - accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "884/884 [==============================] - 0s 24us/sample - loss: 6.3466e-04 - accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "884/884 [==============================] - 0s 25us/sample - loss: 6.0949e-04 - accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "884/884 [==============================] - 0s 25us/sample - loss: 6.1399e-04 - accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "884/884 [==============================] - 0s 25us/sample - loss: 5.9747e-04 - accuracy: 1.0000\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "884/884 [==============================] - 0s 29us/sample - loss: 6.0876e-04 - accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "884/884 [==============================] - 0s 25us/sample - loss: 6.5123e-04 - accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "884/884 [==============================] - 0s 30us/sample - loss: 6.1057e-04 - accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "884/884 [==============================] - 0s 26us/sample - loss: 5.9684e-04 - accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "884/884 [==============================] - 0s 24us/sample - loss: 6.0471e-04 - accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "884/884 [==============================] - 0s 24us/sample - loss: 5.8656e-04 - accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "884/884 [==============================] - 0s 25us/sample - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "884/884 [==============================] - 0s 23us/sample - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "884/884 [==============================] - 0s 25us/sample - loss: 8.0648e-04 - accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "884/884 [==============================] - 0s 24us/sample - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "884/884 [==============================] - 0s 27us/sample - loss: 7.9364e-04 - accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "884/884 [==============================] - 0s 38us/sample - loss: 5.5370e-04 - accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "884/884 [==============================] - 0s 32us/sample - loss: 5.6370e-04 - accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "884/884 [==============================] - 0s 26us/sample - loss: 5.7939e-04 - accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "884/884 [==============================] - 0s 24us/sample - loss: 5.4157e-04 - accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "884/884 [==============================] - 0s 24us/sample - loss: 5.4261e-04 - accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "884/884 [==============================] - 0s 24us/sample - loss: 5.3512e-04 - accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "884/884 [==============================] - 0s 32us/sample - loss: 5.3699e-04 - accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "884/884 [==============================] - 0s 32us/sample - loss: 5.3396e-04 - accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "884/884 [==============================] - 0s 28us/sample - loss: 5.8041e-04 - accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "884/884 [==============================] - 0s 29us/sample - loss: 5.4689e-04 - accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "884/884 [==============================] - 0s 25us/sample - loss: 5.3078e-04 - accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "884/884 [==============================] - 0s 24us/sample - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "884/884 [==============================] - 0s 23us/sample - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "884/884 [==============================] - 0s 23us/sample - loss: 6.8100e-04 - accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "884/884 [==============================] - 0s 24us/sample - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "884/884 [==============================] - 0s 25us/sample - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "884/884 [==============================] - 0s 26us/sample - loss: 7.1734e-04 - accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "884/884 [==============================] - 0s 24us/sample - loss: 9.9360e-04 - accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "884/884 [==============================] - 0s 27us/sample - loss: 6.4934e-04 - accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "884/884 [==============================] - 0s 35us/sample - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "884/884 [==============================] - 0s 36us/sample - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "884/884 [==============================] - 0s 28us/sample - loss: 6.2623e-04 - accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "884/884 [==============================] - 0s 32us/sample - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "884/884 [==============================] - 0s 28us/sample - loss: 8.6424e-04 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "884/884 [==============================] - 0s 27us/sample - loss: 4.9528e-04 - accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "884/884 [==============================] - 0s 37us/sample - loss: 4.7856e-04 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "884/884 [==============================] - 0s 28us/sample - loss: 4.7415e-04 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "884/884 [==============================] - 0s 29us/sample - loss: 4.7483e-04 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "884/884 [==============================] - 0s 37us/sample - loss: 4.9658e-04 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "884/884 [==============================] - 0s 27us/sample - loss: 5.8863e-04 - accuracy: 1.0000\n",
      "Completed Model 5\n",
      "Train on 884 samples\n",
      "Epoch 1/100\n",
      "884/884 [==============================] - 0s 28us/sample - loss: 0.0371 - accuracy: 0.9898\n",
      "Epoch 2/100\n",
      "884/884 [==============================] - 0s 27us/sample - loss: 31.8574 - accuracy: 0.6176\n",
      "Epoch 3/100\n",
      "884/884 [==============================] - 0s 25us/sample - loss: 40.9050 - accuracy: 0.5271\n",
      "Epoch 4/100\n",
      "884/884 [==============================] - 0s 30us/sample - loss: 4.2083 - accuracy: 0.7885\n",
      "Epoch 5/100\n",
      "884/884 [==============================] - 0s 33us/sample - loss: 1.4359 - accuracy: 0.8620\n",
      "Epoch 6/100\n",
      "884/884 [==============================] - 0s 29us/sample - loss: 2.8752 - accuracy: 0.8043\n",
      "Epoch 7/100\n",
      "884/884 [==============================] - 0s 26us/sample - loss: 0.3782 - accuracy: 0.9106\n",
      "Epoch 8/100\n",
      "884/884 [==============================] - 0s 33us/sample - loss: 0.3402 - accuracy: 0.9559\n",
      "Epoch 9/100\n",
      "884/884 [==============================] - 0s 28us/sample - loss: 0.2670 - accuracy: 0.9118\n",
      "Epoch 10/100\n",
      "884/884 [==============================] - 0s 25us/sample - loss: 0.3439 - accuracy: 0.9231\n",
      "Epoch 11/100\n",
      "884/884 [==============================] - 0s 23us/sample - loss: 0.0712 - accuracy: 0.9774\n",
      "Epoch 12/100\n",
      "884/884 [==============================] - 0s 24us/sample - loss: 0.0336 - accuracy: 0.9910\n",
      "Epoch 13/100\n",
      "884/884 [==============================] - 0s 25us/sample - loss: 0.0116 - accuracy: 0.9955\n",
      "Epoch 14/100\n",
      "884/884 [==============================] - 0s 23us/sample - loss: 0.0304 - accuracy: 0.9932\n",
      "Epoch 15/100\n",
      "884/884 [==============================] - 0s 24us/sample - loss: 0.0155 - accuracy: 0.9955\n",
      "Epoch 16/100\n",
      "884/884 [==============================] - 0s 24us/sample - loss: 0.1120 - accuracy: 0.9536\n",
      "Epoch 17/100\n",
      "884/884 [==============================] - 0s 24us/sample - loss: 0.0411 - accuracy: 0.9943\n",
      "Epoch 18/100\n",
      "884/884 [==============================] - 0s 23us/sample - loss: 0.0221 - accuracy: 0.9921\n",
      "Epoch 19/100\n",
      "884/884 [==============================] - 0s 25us/sample - loss: 0.0061 - accuracy: 0.9989\n",
      "Epoch 20/100\n",
      "884/884 [==============================] - 0s 25us/sample - loss: 0.0239 - accuracy: 0.9887\n",
      "Epoch 21/100\n",
      "884/884 [==============================] - 0s 24us/sample - loss: 0.0052 - accuracy: 0.9989\n",
      "Epoch 22/100\n",
      "884/884 [==============================] - 0s 24us/sample - loss: 0.0307 - accuracy: 0.9887\n",
      "Epoch 23/100\n",
      "884/884 [==============================] - 0s 26us/sample - loss: 0.0378 - accuracy: 0.9876\n",
      "Epoch 24/100\n",
      "884/884 [==============================] - 0s 24us/sample - loss: 0.0337 - accuracy: 0.9932\n",
      "Epoch 25/100\n",
      "884/884 [==============================] - 0s 24us/sample - loss: 0.0316 - accuracy: 0.9853\n",
      "Epoch 26/100\n",
      "884/884 [==============================] - 0s 23us/sample - loss: 0.0352 - accuracy: 0.9943\n",
      "Epoch 27/100\n",
      "884/884 [==============================] - 0s 25us/sample - loss: 0.1186 - accuracy: 0.9468\n",
      "Epoch 28/100\n",
      "884/884 [==============================] - 0s 23us/sample - loss: 0.0830 - accuracy: 0.9762\n",
      "Epoch 29/100\n",
      "884/884 [==============================] - 0s 23us/sample - loss: 0.0088 - accuracy: 0.9955\n",
      "Epoch 30/100\n",
      "884/884 [==============================] - 0s 24us/sample - loss: 0.0504 - accuracy: 0.9864\n",
      "Epoch 31/100\n",
      "884/884 [==============================] - 0s 24us/sample - loss: 0.0924 - accuracy: 0.9649\n",
      "Epoch 32/100\n",
      "884/884 [==============================] - 0s 26us/sample - loss: 0.0031 - accuracy: 0.9989\n",
      "Epoch 33/100\n",
      "884/884 [==============================] - ETA: 0s - loss: 0.0075 - accuracy: 1.00 - 0s 26us/sample - loss: 0.0062 - accuracy: 0.9977\n",
      "Epoch 34/100\n",
      "884/884 [==============================] - 0s 32us/sample - loss: 0.0034 - accuracy: 0.9989\n",
      "Epoch 35/100\n",
      "884/884 [==============================] - 0s 27us/sample - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "884/884 [==============================] - 0s 24us/sample - loss: 6.6991e-04 - accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "884/884 [==============================] - 0s 24us/sample - loss: 4.5616e-04 - accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "884/884 [==============================] - 0s 27us/sample - loss: 3.8350e-04 - accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "884/884 [==============================] - 0s 30us/sample - loss: 3.2025e-04 - accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "884/884 [==============================] - 0s 35us/sample - loss: 2.8102e-04 - accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "884/884 [==============================] - 0s 32us/sample - loss: 2.4587e-04 - accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "884/884 [==============================] - 0s 29us/sample - loss: 2.2538e-04 - accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "884/884 [==============================] - 0s 34us/sample - loss: 2.0818e-04 - accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "884/884 [==============================] - 0s 30us/sample - loss: 2.0063e-04 - accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "884/884 [==============================] - 0s 25us/sample - loss: 2.0415e-04 - accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "884/884 [==============================] - 0s 23us/sample - loss: 1.9854e-04 - accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "884/884 [==============================] - 0s 23us/sample - loss: 2.0039e-04 - accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "884/884 [==============================] - 0s 24us/sample - loss: 1.9814e-04 - accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "884/884 [==============================] - 0s 25us/sample - loss: 2.0304e-04 - accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "884/884 [==============================] - 0s 23us/sample - loss: 2.0572e-04 - accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "884/884 [==============================] - 0s 27us/sample - loss: 1.9902e-04 - accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "884/884 [==============================] - 0s 29us/sample - loss: 1.9477e-04 - accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "884/884 [==============================] - 0s 28us/sample - loss: 2.0414e-04 - accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "884/884 [==============================] - 0s 26us/sample - loss: 1.9437e-04 - accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "884/884 [==============================] - 0s 32us/sample - loss: 1.9691e-04 - accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "884/884 [==============================] - 0s 25us/sample - loss: 1.9276e-04 - accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "884/884 [==============================] - 0s 29us/sample - loss: 1.9734e-04 - accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "884/884 [==============================] - 0s 30us/sample - loss: 1.9239e-04 - accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "884/884 [==============================] - 0s 25us/sample - loss: 1.9271e-04 - accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "884/884 [==============================] - 0s 53us/sample - loss: 1.9106e-04 - accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "884/884 [==============================] - 0s 59us/sample - loss: 1.9307e-04 - accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "884/884 [==============================] - 0s 28us/sample - loss: 1.8869e-04 - accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "884/884 [==============================] - 0s 46us/sample - loss: 1.8971e-04 - accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "884/884 [==============================] - 0s 37us/sample - loss: 1.8899e-04 - accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "884/884 [==============================] - 0s 32us/sample - loss: 1.8793e-04 - accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "884/884 [==============================] - 0s 41us/sample - loss: 1.9068e-04 - accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "884/884 [==============================] - 0s 29us/sample - loss: 1.8646e-04 - accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "884/884 [==============================] - 0s 46us/sample - loss: 1.8660e-04 - accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "884/884 [==============================] - 0s 53us/sample - loss: 1.8664e-04 - accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "884/884 [==============================] - 0s 51us/sample - loss: 1.8464e-04 - accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "884/884 [==============================] - 0s 67us/sample - loss: 1.8584e-04 - accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "884/884 [==============================] - 0s 37us/sample - loss: 1.8958e-04 - accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "884/884 [==============================] - 0s 35us/sample - loss: 1.8475e-04 - accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "884/884 [==============================] - 0s 36us/sample - loss: 1.8961e-04 - accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "884/884 [==============================] - 0s 39us/sample - loss: 1.8331e-04 - accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "884/884 [==============================] - 0s 33us/sample - loss: 1.8569e-04 - accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "884/884 [==============================] - 0s 28us/sample - loss: 1.8072e-04 - accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "884/884 [==============================] - 0s 49us/sample - loss: 1.8117e-04 - accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "884/884 [==============================] - 0s 51us/sample - loss: 1.8037e-04 - accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "884/884 [==============================] - 0s 42us/sample - loss: 1.7930e-04 - accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "884/884 [==============================] - 0s 47us/sample - loss: 1.8172e-04 - accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "884/884 [==============================] - 0s 49us/sample - loss: 1.8043e-04 - accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "884/884 [==============================] - 0s 32us/sample - loss: 1.7838e-04 - accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "884/884 [==============================] - 0s 42us/sample - loss: 1.7768e-04 - accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "884/884 [==============================] - 0s 41us/sample - loss: 1.7766e-04 - accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "884/884 [==============================] - 0s 36us/sample - loss: 1.7604e-04 - accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "884/884 [==============================] - 0s 41us/sample - loss: 1.7590e-04 - accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "884/884 [==============================] - 0s 36us/sample - loss: 1.7520e-04 - accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "884/884 [==============================] - 0s 47us/sample - loss: 1.7539e-04 - accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "884/884 [==============================] - 0s 29us/sample - loss: 1.7320e-04 - accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "884/884 [==============================] - 0s 23us/sample - loss: 1.7390e-04 - accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "884/884 [==============================] - 0s 24us/sample - loss: 1.8853e-04 - accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "884/884 [==============================] - 0s 25us/sample - loss: 1.8069e-04 - accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "884/884 [==============================] - 0s 33us/sample - loss: 1.8686e-04 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "884/884 [==============================] - 0s 55us/sample - loss: 1.7606e-04 - accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "884/884 [==============================] - 0s 34us/sample - loss: 1.7890e-04 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "884/884 [==============================] - 0s 30us/sample - loss: 1.7198e-04 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "884/884 [==============================] - 0s 30us/sample - loss: 1.7241e-04 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "884/884 [==============================] - 0s 47us/sample - loss: 1.7025e-04 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "884/884 [==============================] - 0s 29us/sample - loss: 1.7589e-04 - accuracy: 1.0000\n",
      "Completed Model 6\n",
      "Train on 884 samples\n",
      "Epoch 1/100\n",
      "884/884 [==============================] - 0s 38us/sample - loss: 0.0995 - accuracy: 0.9683\n",
      "Epoch 2/100\n",
      "884/884 [==============================] - 0s 59us/sample - loss: 1.0080 - accuracy: 0.8575\n",
      "Epoch 3/100\n",
      "884/884 [==============================] - 0s 36us/sample - loss: 56.5403 - accuracy: 0.5034\n",
      "Epoch 4/100\n",
      "884/884 [==============================] - 0s 32us/sample - loss: 37.5772 - accuracy: 0.5271\n",
      "Epoch 5/100\n",
      "884/884 [==============================] - 0s 37us/sample - loss: 26.8643 - accuracy: 0.6018\n",
      "Epoch 6/100\n",
      "884/884 [==============================] - 0s 32us/sample - loss: 54.5128 - accuracy: 0.5249\n",
      "Epoch 7/100\n",
      "884/884 [==============================] - 0s 38us/sample - loss: 29.0678 - accuracy: 0.5532\n",
      "Epoch 8/100\n",
      "884/884 [==============================] - 0s 34us/sample - loss: 7.1821 - accuracy: 0.8020\n",
      "Epoch 9/100\n",
      "884/884 [==============================] - 0s 49us/sample - loss: 9.8719 - accuracy: 0.6154\n",
      "Epoch 10/100\n",
      "884/884 [==============================] - 0s 52us/sample - loss: 4.4338 - accuracy: 0.7896\n",
      "Epoch 11/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "884/884 [==============================] - 0s 27us/sample - loss: 5.2048 - accuracy: 0.7251\n",
      "Epoch 12/100\n",
      "884/884 [==============================] - 0s 26us/sample - loss: 3.3959 - accuracy: 0.8077\n",
      "Epoch 13/100\n",
      "884/884 [==============================] - 0s 28us/sample - loss: 1.9299 - accuracy: 0.7602\n",
      "Epoch 14/100\n",
      "884/884 [==============================] - 0s 26us/sample - loss: 1.4900 - accuracy: 0.8563\n",
      "Epoch 15/100\n",
      "884/884 [==============================] - 0s 28us/sample - loss: 0.9169 - accuracy: 0.8541\n",
      "Epoch 16/100\n",
      "884/884 [==============================] - 0s 36us/sample - loss: 0.9080 - accuracy: 0.8303\n",
      "Epoch 17/100\n",
      "884/884 [==============================] - 0s 37us/sample - loss: 0.5720 - accuracy: 0.8869\n",
      "Epoch 18/100\n",
      "884/884 [==============================] - 0s 39us/sample - loss: 0.3998 - accuracy: 0.8971\n",
      "Epoch 19/100\n",
      "884/884 [==============================] - 0s 28us/sample - loss: 0.2602 - accuracy: 0.9310\n",
      "Epoch 20/100\n",
      "884/884 [==============================] - 0s 33us/sample - loss: 0.3555 - accuracy: 0.9423\n",
      "Epoch 21/100\n",
      "884/884 [==============================] - 0s 30us/sample - loss: 0.2571 - accuracy: 0.9672\n",
      "Epoch 22/100\n",
      "884/884 [==============================] - 0s 33us/sample - loss: 0.2826 - accuracy: 0.9163\n",
      "Epoch 23/100\n",
      "884/884 [==============================] - 0s 30us/sample - loss: 0.1093 - accuracy: 0.9683\n",
      "Epoch 24/100\n",
      "884/884 [==============================] - 0s 43us/sample - loss: 0.2773 - accuracy: 0.9785\n",
      "Epoch 25/100\n",
      "884/884 [==============================] - 0s 37us/sample - loss: 0.5221 - accuracy: 0.8597\n",
      "Epoch 26/100\n",
      "884/884 [==============================] - 0s 32us/sample - loss: 0.0605 - accuracy: 0.9864\n",
      "Epoch 27/100\n",
      "884/884 [==============================] - 0s 32us/sample - loss: 0.0574 - accuracy: 0.9774\n",
      "Epoch 28/100\n",
      "884/884 [==============================] - 0s 27us/sample - loss: 0.0454 - accuracy: 0.9887\n",
      "Epoch 29/100\n",
      "884/884 [==============================] - 0s 33us/sample - loss: 0.0534 - accuracy: 0.9762\n",
      "Epoch 30/100\n",
      "884/884 [==============================] - 0s 38us/sample - loss: 0.0249 - accuracy: 0.9921\n",
      "Epoch 31/100\n",
      "884/884 [==============================] - 0s 38us/sample - loss: 0.0471 - accuracy: 0.9921\n",
      "Epoch 32/100\n",
      "884/884 [==============================] - 0s 33us/sample - loss: 0.0661 - accuracy: 0.9751\n",
      "Epoch 33/100\n",
      "884/884 [==============================] - 0s 35us/sample - loss: 0.0238 - accuracy: 0.9921\n",
      "Epoch 34/100\n",
      "884/884 [==============================] - 0s 47us/sample - loss: 0.0355 - accuracy: 0.9921\n",
      "Epoch 35/100\n",
      "884/884 [==============================] - 0s 36us/sample - loss: 0.0192 - accuracy: 0.9921\n",
      "Epoch 36/100\n",
      "884/884 [==============================] - 0s 34us/sample - loss: 0.0271 - accuracy: 0.9943\n",
      "Epoch 37/100\n",
      "884/884 [==============================] - 0s 35us/sample - loss: 0.0644 - accuracy: 0.9751\n",
      "Epoch 38/100\n",
      "884/884 [==============================] - 0s 33us/sample - loss: 0.0216 - accuracy: 0.9932\n",
      "Epoch 39/100\n",
      "884/884 [==============================] - 0s 37us/sample - loss: 0.0115 - accuracy: 0.9955\n",
      "Epoch 40/100\n",
      "884/884 [==============================] - 0s 33us/sample - loss: 0.0124 - accuracy: 0.9955\n",
      "Epoch 41/100\n",
      "884/884 [==============================] - 0s 26us/sample - loss: 0.0072 - accuracy: 0.9966\n",
      "Epoch 42/100\n",
      "884/884 [==============================] - 0s 32us/sample - loss: 0.0089 - accuracy: 0.9966\n",
      "Epoch 43/100\n",
      "884/884 [==============================] - 0s 32us/sample - loss: 0.0113 - accuracy: 0.9966\n",
      "Epoch 44/100\n",
      "884/884 [==============================] - 0s 36us/sample - loss: 0.0085 - accuracy: 0.9966\n",
      "Epoch 45/100\n",
      "884/884 [==============================] - 0s 30us/sample - loss: 0.0060 - accuracy: 0.9977\n",
      "Epoch 46/100\n",
      "884/884 [==============================] - 0s 32us/sample - loss: 0.0055 - accuracy: 0.9977\n",
      "Epoch 47/100\n",
      "884/884 [==============================] - 0s 29us/sample - loss: 0.0051 - accuracy: 0.9977\n",
      "Epoch 48/100\n",
      "884/884 [==============================] - 0s 32us/sample - loss: 0.0063 - accuracy: 0.9977\n",
      "Epoch 49/100\n",
      "884/884 [==============================] - 0s 29us/sample - loss: 0.0070 - accuracy: 0.9966\n",
      "Epoch 50/100\n",
      "884/884 [==============================] - 0s 28us/sample - loss: 0.0076 - accuracy: 0.9977\n",
      "Epoch 51/100\n",
      "884/884 [==============================] - 0s 30us/sample - loss: 0.0240 - accuracy: 0.9932\n",
      "Epoch 52/100\n",
      "884/884 [==============================] - 0s 36us/sample - loss: 0.0258 - accuracy: 0.9910\n",
      "Epoch 53/100\n",
      "884/884 [==============================] - 0s 33us/sample - loss: 0.0065 - accuracy: 0.9966\n",
      "Epoch 54/100\n",
      "884/884 [==============================] - 0s 33us/sample - loss: 0.0057 - accuracy: 0.9977\n",
      "Epoch 55/100\n",
      "884/884 [==============================] - 0s 35us/sample - loss: 0.0235 - accuracy: 0.9910\n",
      "Epoch 56/100\n",
      "884/884 [==============================] - 0s 32us/sample - loss: 0.0140 - accuracy: 0.9943\n",
      "Epoch 57/100\n",
      "884/884 [==============================] - 0s 29us/sample - loss: 0.0042 - accuracy: 0.9989\n",
      "Epoch 58/100\n",
      "884/884 [==============================] - 0s 27us/sample - loss: 0.0027 - accuracy: 0.9989\n",
      "Epoch 59/100\n",
      "884/884 [==============================] - 0s 36us/sample - loss: 0.0025 - accuracy: 0.9989\n",
      "Epoch 60/100\n",
      "884/884 [==============================] - 0s 35us/sample - loss: 0.0021 - accuracy: 0.9989\n",
      "Epoch 61/100\n",
      "884/884 [==============================] - 0s 34us/sample - loss: 0.0078 - accuracy: 0.9943\n",
      "Epoch 62/100\n",
      "884/884 [==============================] - 0s 29us/sample - loss: 0.0160 - accuracy: 0.9943\n",
      "Epoch 63/100\n",
      "884/884 [==============================] - 0s 28us/sample - loss: 0.0072 - accuracy: 0.9977\n",
      "Epoch 64/100\n",
      "884/884 [==============================] - 0s 32us/sample - loss: 0.0023 - accuracy: 0.9989\n",
      "Epoch 65/100\n",
      "884/884 [==============================] - 0s 41us/sample - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "884/884 [==============================] - 0s 32us/sample - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "884/884 [==============================] - 0s 37us/sample - loss: 0.0019 - accuracy: 0.9989\n",
      "Epoch 68/100\n",
      "884/884 [==============================] - 0s 33us/sample - loss: 0.0018 - accuracy: 0.9989\n",
      "Epoch 69/100\n",
      "884/884 [==============================] - 0s 33us/sample - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "884/884 [==============================] - 0s 30us/sample - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "884/884 [==============================] - 0s 33us/sample - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "884/884 [==============================] - 0s 29us/sample - loss: 0.0020 - accuracy: 0.9989\n",
      "Epoch 73/100\n",
      "884/884 [==============================] - 0s 29us/sample - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "884/884 [==============================] - 0s 32us/sample - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "884/884 [==============================] - 0s 28us/sample - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "884/884 [==============================] - 0s 39us/sample - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "884/884 [==============================] - 0s 30us/sample - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "884/884 [==============================] - 0s 29us/sample - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "884/884 [==============================] - 0s 28us/sample - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "884/884 [==============================] - 0s 28us/sample - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "884/884 [==============================] - 0s 28us/sample - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "884/884 [==============================] - 0s 32us/sample - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "884/884 [==============================] - 0s 30us/sample - loss: 9.5443e-04 - accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "884/884 [==============================] - 0s 36us/sample - loss: 9.9586e-04 - accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "884/884 [==============================] - 0s 28us/sample - loss: 9.4404e-04 - accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "884/884 [==============================] - 0s 37us/sample - loss: 9.3007e-04 - accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "884/884 [==============================] - 0s 28us/sample - loss: 9.2848e-04 - accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "884/884 [==============================] - 0s 32us/sample - loss: 9.0377e-04 - accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89/100\n",
      "884/884 [==============================] - 0s 29us/sample - loss: 8.8725e-04 - accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "884/884 [==============================] - 0s 30us/sample - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "884/884 [==============================] - 0s 28us/sample - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "884/884 [==============================] - 0s 27us/sample - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "884/884 [==============================] - 0s 28us/sample - loss: 8.1717e-04 - accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "884/884 [==============================] - 0s 29us/sample - loss: 8.7686e-04 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "884/884 [==============================] - 0s 25us/sample - loss: 9.7610e-04 - accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "884/884 [==============================] - 0s 26us/sample - loss: 8.6025e-04 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "884/884 [==============================] - 0s 37us/sample - loss: 7.8951e-04 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "884/884 [==============================] - 0s 27us/sample - loss: 7.6231e-04 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "884/884 [==============================] - 0s 35us/sample - loss: 7.5959e-04 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "884/884 [==============================] - 0s 32us/sample - loss: 7.4093e-04 - accuracy: 1.0000\n",
      "Completed Model 7\n",
      "Train on 884 samples\n",
      "Epoch 1/100\n",
      "884/884 [==============================] - 0s 38us/sample - loss: 0.0074 - accuracy: 0.9989\n",
      "Epoch 2/100\n",
      "884/884 [==============================] - 0s 26us/sample - loss: 0.0073 - accuracy: 0.9989\n",
      "Epoch 3/100\n",
      "884/884 [==============================] - 0s 41us/sample - loss: 0.0068 - accuracy: 0.9989\n",
      "Epoch 4/100\n",
      "884/884 [==============================] - 0s 39us/sample - loss: 0.0073 - accuracy: 0.9989\n",
      "Epoch 5/100\n",
      "884/884 [==============================] - 0s 34us/sample - loss: 0.0068 - accuracy: 0.9989\n",
      "Epoch 6/100\n",
      "884/884 [==============================] - 0s 27us/sample - loss: 0.0067 - accuracy: 0.9989\n",
      "Epoch 7/100\n",
      "884/884 [==============================] - 0s 28us/sample - loss: 0.0065 - accuracy: 0.9989\n",
      "Epoch 8/100\n",
      "884/884 [==============================] - 0s 32us/sample - loss: 0.0855 - accuracy: 0.9695\n",
      "Epoch 9/100\n",
      "884/884 [==============================] - 0s 34us/sample - loss: 0.0538 - accuracy: 0.9864\n",
      "Epoch 10/100\n",
      "884/884 [==============================] - 0s 34us/sample - loss: 0.0066 - accuracy: 0.9977\n",
      "Epoch 11/100\n",
      "884/884 [==============================] - 0s 39us/sample - loss: 0.0089 - accuracy: 0.9966\n",
      "Epoch 12/100\n",
      "884/884 [==============================] - 0s 32us/sample - loss: 0.0052 - accuracy: 0.9977\n",
      "Epoch 13/100\n",
      "884/884 [==============================] - 0s 34us/sample - loss: 0.0038 - accuracy: 0.9989\n",
      "Epoch 14/100\n",
      "884/884 [==============================] - 0s 29us/sample - loss: 0.0253 - accuracy: 0.9977\n",
      "Epoch 15/100\n",
      "884/884 [==============================] - 0s 37us/sample - loss: 0.0487 - accuracy: 0.9864\n",
      "Epoch 16/100\n",
      "884/884 [==============================] - 0s 27us/sample - loss: 0.0061 - accuracy: 0.9989\n",
      "Epoch 17/100\n",
      "884/884 [==============================] - 0s 34us/sample - loss: 0.0025 - accuracy: 0.9989\n",
      "Epoch 18/100\n",
      "884/884 [==============================] - 0s 32us/sample - loss: 0.0241 - accuracy: 0.9932\n",
      "Epoch 19/100\n",
      "884/884 [==============================] - 0s 33us/sample - loss: 0.0276 - accuracy: 0.9921\n",
      "Epoch 20/100\n",
      "884/884 [==============================] - 0s 29us/sample - loss: 0.0090 - accuracy: 0.9966\n",
      "Epoch 21/100\n",
      "884/884 [==============================] - 0s 38us/sample - loss: 0.0030 - accuracy: 0.9989\n",
      "Epoch 22/100\n",
      "884/884 [==============================] - 0s 30us/sample - loss: 0.0018 - accuracy: 0.9989\n",
      "Epoch 23/100\n",
      "884/884 [==============================] - 0s 30us/sample - loss: 0.0017 - accuracy: 0.9989\n",
      "Epoch 24/100\n",
      "884/884 [==============================] - 0s 30us/sample - loss: 0.0018 - accuracy: 0.9989\n",
      "Epoch 25/100\n",
      "884/884 [==============================] - 0s 27us/sample - loss: 0.0026 - accuracy: 0.9989\n",
      "Epoch 26/100\n",
      "884/884 [==============================] - 0s 30us/sample - loss: 0.0022 - accuracy: 0.9989\n",
      "Epoch 27/100\n",
      "884/884 [==============================] - 0s 21us/sample - loss: 0.0014 - accuracy: 0.9989\n",
      "Epoch 28/100\n",
      "884/884 [==============================] - 0s 25us/sample - loss: 0.0059 - accuracy: 0.9977\n",
      "Epoch 29/100\n",
      "884/884 [==============================] - 0s 24us/sample - loss: 0.0114 - accuracy: 0.9966\n",
      "Epoch 30/100\n",
      "884/884 [==============================] - 0s 34us/sample - loss: 0.0083 - accuracy: 0.9966\n",
      "Epoch 31/100\n",
      "884/884 [==============================] - 0s 30us/sample - loss: 0.0028 - accuracy: 0.9989\n",
      "Epoch 32/100\n",
      "884/884 [==============================] - 0s 38us/sample - loss: 0.0015 - accuracy: 0.9989\n",
      "Epoch 33/100\n",
      "884/884 [==============================] - 0s 34us/sample - loss: 0.0057 - accuracy: 0.9989\n",
      "Epoch 34/100\n",
      "884/884 [==============================] - 0s 30us/sample - loss: 0.0069 - accuracy: 0.9955\n",
      "Epoch 35/100\n",
      "884/884 [==============================] - 0s 37us/sample - loss: 0.0118 - accuracy: 0.9966\n",
      "Epoch 36/100\n",
      "884/884 [==============================] - 0s 34us/sample - loss: 0.0060 - accuracy: 0.9977\n",
      "Epoch 37/100\n",
      "884/884 [==============================] - 0s 33us/sample - loss: 0.0014 - accuracy: 0.9989\n",
      "Epoch 38/100\n",
      "884/884 [==============================] - 0s 38us/sample - loss: 9.1151e-04 - accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "884/884 [==============================] - 0s 28us/sample - loss: 0.0032 - accuracy: 0.9977\n",
      "Epoch 40/100\n",
      "884/884 [==============================] - 0s 39us/sample - loss: 0.0051 - accuracy: 0.9977\n",
      "Epoch 41/100\n",
      "884/884 [==============================] - 0s 36us/sample - loss: 0.0093 - accuracy: 0.9977\n",
      "Epoch 42/100\n",
      "884/884 [==============================] - 0s 28us/sample - loss: 0.0041 - accuracy: 0.9977\n",
      "Epoch 43/100\n",
      "884/884 [==============================] - 0s 39us/sample - loss: 0.0016 - accuracy: 0.9989\n",
      "Epoch 44/100\n",
      "884/884 [==============================] - 0s 33us/sample - loss: 8.6864e-04 - accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "884/884 [==============================] - 0s 38us/sample - loss: 4.5132e-04 - accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "884/884 [==============================] - 0s 33us/sample - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "884/884 [==============================] - 0s 32us/sample - loss: 0.0015 - accuracy: 0.9989\n",
      "Epoch 48/100\n",
      "884/884 [==============================] - 0s 28us/sample - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 49/100\n",
      "884/884 [==============================] - 0s 32us/sample - loss: 0.0034 - accuracy: 0.9977\n",
      "Epoch 50/100\n",
      "884/884 [==============================] - 0s 27us/sample - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "884/884 [==============================] - 0s 38us/sample - loss: 6.1040e-04 - accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "884/884 [==============================] - 0s 30us/sample - loss: 3.5947e-04 - accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "884/884 [==============================] - 0s 26us/sample - loss: 6.7472e-04 - accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "884/884 [==============================] - 0s 30us/sample - loss: 0.0014 - accuracy: 0.9989\n",
      "Epoch 55/100\n",
      "884/884 [==============================] - 0s 43us/sample - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "884/884 [==============================] - 0s 36us/sample - loss: 7.7781e-04 - accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "884/884 [==============================] - 0s 34us/sample - loss: 5.5210e-04 - accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "884/884 [==============================] - 0s 25us/sample - loss: 3.4301e-04 - accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "884/884 [==============================] - 0s 40us/sample - loss: 3.3489e-04 - accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "884/884 [==============================] - 0s 37us/sample - loss: 3.1752e-04 - accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "884/884 [==============================] - 0s 49us/sample - loss: 3.2772e-04 - accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "884/884 [==============================] - 0s 27us/sample - loss: 3.1156e-04 - accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "884/884 [==============================] - 0s 25us/sample - loss: 3.1482e-04 - accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "884/884 [==============================] - 0s 32us/sample - loss: 2.8698e-04 - accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "884/884 [==============================] - 0s 27us/sample - loss: 3.7192e-04 - accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "884/884 [==============================] - 0s 26us/sample - loss: 3.3238e-04 - accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "884/884 [==============================] - 0s 29us/sample - loss: 2.9279e-04 - accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "884/884 [==============================] - 0s 24us/sample - loss: 2.8332e-04 - accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "884/884 [==============================] - 0s 25us/sample - loss: 2.9579e-04 - accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "884/884 [==============================] - 0s 27us/sample - loss: 2.8629e-04 - accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "884/884 [==============================] - 0s 24us/sample - loss: 3.2321e-04 - accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "884/884 [==============================] - 0s 25us/sample - loss: 3.2722e-04 - accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "884/884 [==============================] - 0s 26us/sample - loss: 3.0787e-04 - accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "884/884 [==============================] - 0s 28us/sample - loss: 2.7269e-04 - accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "884/884 [==============================] - 0s 25us/sample - loss: 3.4820e-04 - accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "884/884 [==============================] - 0s 25us/sample - loss: 4.2591e-04 - accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "884/884 [==============================] - 0s 25us/sample - loss: 3.8071e-04 - accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "884/884 [==============================] - 0s 26us/sample - loss: 2.8382e-04 - accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "884/884 [==============================] - 0s 24us/sample - loss: 2.7462e-04 - accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "884/884 [==============================] - 0s 28us/sample - loss: 2.7044e-04 - accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "884/884 [==============================] - 0s 24us/sample - loss: 2.5506e-04 - accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "884/884 [==============================] - 0s 26us/sample - loss: 2.7483e-04 - accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "884/884 [==============================] - 0s 24us/sample - loss: 2.6081e-04 - accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "884/884 [==============================] - 0s 25us/sample - loss: 2.4882e-04 - accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "884/884 [==============================] - 0s 26us/sample - loss: 2.5161e-04 - accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "884/884 [==============================] - 0s 23us/sample - loss: 2.4647e-04 - accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "884/884 [==============================] - 0s 26us/sample - loss: 2.4018e-04 - accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "884/884 [==============================] - 0s 25us/sample - loss: 2.6634e-04 - accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "884/884 [==============================] - 0s 25us/sample - loss: 2.5289e-04 - accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "884/884 [==============================] - 0s 24us/sample - loss: 2.5709e-04 - accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "884/884 [==============================] - 0s 29us/sample - loss: 2.2946e-04 - accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "884/884 [==============================] - 0s 37us/sample - loss: 2.5591e-04 - accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "884/884 [==============================] - 0s 37us/sample - loss: 2.3137e-04 - accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "884/884 [==============================] - 0s 32us/sample - loss: 2.4574e-04 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "884/884 [==============================] - 0s 30us/sample - loss: 2.5060e-04 - accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "884/884 [==============================] - 0s 29us/sample - loss: 2.2786e-04 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "884/884 [==============================] - 0s 35us/sample - loss: 2.5180e-04 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "884/884 [==============================] - 0s 39us/sample - loss: 2.2626e-04 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "884/884 [==============================] - 0s 45us/sample - loss: 2.1383e-04 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "884/884 [==============================] - 0s 45us/sample - loss: 2.1645e-04 - accuracy: 1.0000\n",
      "Completed Model 8\n",
      "Train on 884 samples\n",
      "Epoch 1/100\n",
      "884/884 [==============================] - 0s 58us/sample - loss: 0.1695 - accuracy: 0.9593\n",
      "Epoch 2/100\n",
      "884/884 [==============================] - 0s 55us/sample - loss: 0.3220 - accuracy: 0.9400\n",
      "Epoch 3/100\n",
      "884/884 [==============================] - 0s 49us/sample - loss: 0.0442 - accuracy: 0.9842\n",
      "Epoch 4/100\n",
      "884/884 [==============================] - 0s 59us/sample - loss: 0.3253 - accuracy: 0.9344\n",
      "Epoch 5/100\n",
      "884/884 [==============================] - 0s 43us/sample - loss: 2.6718 - accuracy: 0.8190\n",
      "Epoch 6/100\n",
      "884/884 [==============================] - 0s 41us/sample - loss: 52.0631 - accuracy: 0.5023\n",
      "Epoch 7/100\n",
      "884/884 [==============================] - 0s 41us/sample - loss: 24.8970 - accuracy: 0.5995\n",
      "Epoch 8/100\n",
      "884/884 [==============================] - 0s 38us/sample - loss: 55.8135 - accuracy: 0.5192\n",
      "Epoch 9/100\n",
      "884/884 [==============================] - 0s 35us/sample - loss: 19.6440 - accuracy: 0.6165\n",
      "Epoch 10/100\n",
      "884/884 [==============================] - 0s 39us/sample - loss: 4.9628 - accuracy: 0.7749\n",
      "Epoch 11/100\n",
      "884/884 [==============================] - 0s 37us/sample - loss: 2.5272 - accuracy: 0.8722\n",
      "Epoch 12/100\n",
      "884/884 [==============================] - 0s 36us/sample - loss: 1.4370 - accuracy: 0.8518\n",
      "Epoch 13/100\n",
      "884/884 [==============================] - 0s 59us/sample - loss: 1.3019 - accuracy: 0.8213\n",
      "Epoch 14/100\n",
      "884/884 [==============================] - 0s 38us/sample - loss: 0.6566 - accuracy: 0.9084\n",
      "Epoch 15/100\n",
      "884/884 [==============================] - 0s 42us/sample - loss: 0.5310 - accuracy: 0.9005\n",
      "Epoch 16/100\n",
      "884/884 [==============================] - 0s 39us/sample - loss: 0.5065 - accuracy: 0.9140\n",
      "Epoch 17/100\n",
      "884/884 [==============================] - 0s 35us/sample - loss: 0.3297 - accuracy: 0.9638\n",
      "Epoch 18/100\n",
      "884/884 [==============================] - 0s 35us/sample - loss: 0.1902 - accuracy: 0.9559\n",
      "Epoch 19/100\n",
      "884/884 [==============================] - 0s 36us/sample - loss: 0.1100 - accuracy: 0.9649\n",
      "Epoch 20/100\n",
      "884/884 [==============================] - 0s 99us/sample - loss: 0.1623 - accuracy: 0.9695\n",
      "Epoch 21/100\n",
      "884/884 [==============================] - 0s 120us/sample - loss: 0.0756 - accuracy: 0.9830\n",
      "Epoch 22/100\n",
      "884/884 [==============================] - 0s 58us/sample - loss: 0.0990 - accuracy: 0.9683\n",
      "Epoch 23/100\n",
      "884/884 [==============================] - 0s 47us/sample - loss: 0.1151 - accuracy: 0.9887\n",
      "Epoch 24/100\n",
      "884/884 [==============================] - 0s 80us/sample - loss: 0.2177 - accuracy: 0.9378\n",
      "Epoch 25/100\n",
      "884/884 [==============================] - 0s 79us/sample - loss: 0.0682 - accuracy: 0.9864\n",
      "Epoch 26/100\n",
      "884/884 [==============================] - 0s 58us/sample - loss: 0.0859 - accuracy: 0.9740\n",
      "Epoch 27/100\n",
      "884/884 [==============================] - 0s 103us/sample - loss: 0.0279 - accuracy: 0.9887\n",
      "Epoch 28/100\n",
      "884/884 [==============================] - 0s 51us/sample - loss: 0.0107 - accuracy: 0.9955\n",
      "Epoch 29/100\n",
      "884/884 [==============================] - 0s 40us/sample - loss: 0.0065 - accuracy: 0.9966\n",
      "Epoch 30/100\n",
      "884/884 [==============================] - 0s 49us/sample - loss: 0.0679 - accuracy: 0.9842\n",
      "Epoch 31/100\n",
      "884/884 [==============================] - 0s 53us/sample - loss: 0.0753 - accuracy: 0.9796\n",
      "Epoch 32/100\n",
      "884/884 [==============================] - 0s 77us/sample - loss: 0.0117 - accuracy: 0.9943\n",
      "Epoch 33/100\n",
      "884/884 [==============================] - 0s 48us/sample - loss: 0.0190 - accuracy: 0.9921\n",
      "Epoch 34/100\n",
      "884/884 [==============================] - 0s 52us/sample - loss: 0.0084 - accuracy: 0.9955\n",
      "Epoch 35/100\n",
      "884/884 [==============================] - 0s 59us/sample - loss: 0.0171 - accuracy: 0.9910\n",
      "Epoch 36/100\n",
      "884/884 [==============================] - 0s 103us/sample - loss: 0.0480 - accuracy: 0.9808\n",
      "Epoch 37/100\n",
      "884/884 [==============================] - 0s 126us/sample - loss: 0.0090 - accuracy: 0.9955\n",
      "Epoch 38/100\n",
      "884/884 [==============================] - 0s 57us/sample - loss: 0.0023 - accuracy: 0.9989\n",
      "Epoch 39/100\n",
      "884/884 [==============================] - 0s 51us/sample - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "884/884 [==============================] - 0s 48us/sample - loss: 0.0061 - accuracy: 0.9977\n",
      "Epoch 41/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "884/884 [==============================] - 0s 41us/sample - loss: 0.0108 - accuracy: 0.9943\n",
      "Epoch 42/100\n",
      "884/884 [==============================] - 0s 36us/sample - loss: 0.0073 - accuracy: 0.9966\n",
      "Epoch 43/100\n",
      "884/884 [==============================] - 0s 55us/sample - loss: 0.0025 - accuracy: 0.9989\n",
      "Epoch 44/100\n",
      "884/884 [==============================] - 0s 42us/sample - loss: 0.0101 - accuracy: 0.9943\n",
      "Epoch 45/100\n",
      "884/884 [==============================] - 0s 45us/sample - loss: 0.0131 - accuracy: 0.9932\n",
      "Epoch 46/100\n",
      "884/884 [==============================] - 0s 44us/sample - loss: 0.0040 - accuracy: 0.9966\n",
      "Epoch 47/100\n",
      "884/884 [==============================] - 0s 42us/sample - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "884/884 [==============================] - 0s 83us/sample - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "884/884 [==============================] - 0s 35us/sample - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "884/884 [==============================] - 0s 46us/sample - loss: 0.0022 - accuracy: 0.9989\n",
      "Epoch 51/100\n",
      "884/884 [==============================] - 0s 61us/sample - loss: 0.0048 - accuracy: 0.9977\n",
      "Epoch 52/100\n",
      "884/884 [==============================] - 0s 72us/sample - loss: 0.0031 - accuracy: 0.9989\n",
      "Epoch 53/100\n",
      "884/884 [==============================] - 0s 81us/sample - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "884/884 [==============================] - 0s 43us/sample - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "884/884 [==============================] - 0s 57us/sample - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "884/884 [==============================] - 0s 54us/sample - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "884/884 [==============================] - 0s 52us/sample - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "884/884 [==============================] - 0s 102us/sample - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "884/884 [==============================] - 0s 44us/sample - loss: 0.0023 - accuracy: 0.9989\n",
      "Epoch 60/100\n",
      "884/884 [==============================] - 0s 48us/sample - loss: 0.0055 - accuracy: 0.9966\n",
      "Epoch 61/100\n",
      "884/884 [==============================] - 0s 42us/sample - loss: 0.0028 - accuracy: 0.9977\n",
      "Epoch 62/100\n",
      "884/884 [==============================] - 0s 37us/sample - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "884/884 [==============================] - 0s 40us/sample - loss: 0.0025 - accuracy: 0.9989\n",
      "Epoch 64/100\n",
      "884/884 [==============================] - 0s 36us/sample - loss: 0.0094 - accuracy: 0.9966\n",
      "Epoch 65/100\n",
      "884/884 [==============================] - 0s 39us/sample - loss: 0.0068 - accuracy: 0.9955\n",
      "Epoch 66/100\n",
      "884/884 [==============================] - 0s 37us/sample - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "884/884 [==============================] - 0s 35us/sample - loss: 0.0023 - accuracy: 0.9989\n",
      "Epoch 68/100\n",
      "884/884 [==============================] - 0s 35us/sample - loss: 0.0048 - accuracy: 0.9977\n",
      "Epoch 69/100\n",
      "884/884 [==============================] - 0s 37us/sample - loss: 0.0052 - accuracy: 0.9977\n",
      "Epoch 70/100\n",
      "884/884 [==============================] - 0s 40us/sample - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "884/884 [==============================] - 0s 42us/sample - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "884/884 [==============================] - 0s 35us/sample - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "884/884 [==============================] - 0s 37us/sample - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "884/884 [==============================] - 0s 36us/sample - loss: 8.5250e-04 - accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "884/884 [==============================] - 0s 40us/sample - loss: 8.2443e-04 - accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "884/884 [==============================] - 0s 40us/sample - loss: 8.6958e-04 - accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "884/884 [==============================] - 0s 39us/sample - loss: 9.9499e-04 - accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "884/884 [==============================] - 0s 36us/sample - loss: 8.8551e-04 - accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "884/884 [==============================] - 0s 47us/sample - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "884/884 [==============================] - 0s 36us/sample - loss: 0.0028 - accuracy: 0.9989\n",
      "Epoch 81/100\n",
      "884/884 [==============================] - 0s 36us/sample - loss: 0.0027 - accuracy: 0.9989\n",
      "Epoch 82/100\n",
      "884/884 [==============================] - 0s 36us/sample - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "884/884 [==============================] - 0s 34us/sample - loss: 7.2733e-04 - accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "884/884 [==============================] - 0s 33us/sample - loss: 6.8325e-04 - accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "884/884 [==============================] - 0s 34us/sample - loss: 6.8728e-04 - accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "884/884 [==============================] - 0s 30us/sample - loss: 6.8704e-04 - accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "884/884 [==============================] - 0s 33us/sample - loss: 6.6087e-04 - accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "884/884 [==============================] - 0s 29us/sample - loss: 6.4568e-04 - accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "884/884 [==============================] - 0s 28us/sample - loss: 6.6643e-04 - accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "884/884 [==============================] - 0s 37us/sample - loss: 7.6832e-04 - accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "884/884 [==============================] - 0s 36us/sample - loss: 7.4789e-04 - accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "884/884 [==============================] - 0s 38us/sample - loss: 6.6456e-04 - accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "884/884 [==============================] - 0s 39us/sample - loss: 8.4434e-04 - accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "884/884 [==============================] - 0s 44us/sample - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "884/884 [==============================] - 0s 39us/sample - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "884/884 [==============================] - 0s 30us/sample - loss: 7.4338e-04 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "884/884 [==============================] - ETA: 0s - loss: 9.7694e-05 - accuracy: 1.00 - 0s 25us/sample - loss: 6.0869e-04 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "884/884 [==============================] - 0s 26us/sample - loss: 5.8456e-04 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "884/884 [==============================] - 0s 28us/sample - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "884/884 [==============================] - 0s 27us/sample - loss: 0.0033 - accuracy: 0.9989\n",
      "Completed Model 9\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(15, input_dim=30, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "models = []\n",
    "for i in np.arange(k):\n",
    "    #creating training dataset and labels for each model run\n",
    "    label0 = np.zeros((split_data0[i].shape[0],1))\n",
    "    label1 = np.ones((train_data1.shape[0],1))\n",
    "    x_train = np.concatenate((split_data0[i],train_data1),axis = 0)\n",
    "    y_train = np.concatenate((label0,label1),axis = 0)\n",
    "    dataset = np.concatenate((x_train,y_train),axis = 1)\n",
    "    np.random.shuffle(dataset)\n",
    "    y_train = dataset[:,30]\n",
    "    x_train = dataset[:,:30]\n",
    "    history = model.fit(x_train, y_train, epochs=100, batch_size=64)\n",
    "    models.append(model)\n",
    "    print(\"Completed Model\",i+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 9)\n"
     ]
    }
   ],
   "source": [
    "predict = []\n",
    "for j in np.arange(k):\n",
    "    p = models[j].predict(test_data)\n",
    "    predict.append(p)\n",
    "predict = np.array(predict)\n",
    "prediction = np.transpose(predict)\n",
    "# print(prediction.shape)\n",
    "prediction = prediction[0]\n",
    "print(prediction.shape)\n",
    "prediction=1*(prediction>=0.5)\n",
    "\n",
    "result = []\n",
    "for i in np.arange(prediction.shape[0]):\n",
    "    c=0\n",
    "    for j in np.arange(k):\n",
    "        if prediction[i][j]==0:\n",
    "            c=c+1\n",
    "    if c>k-c:\n",
    "        result.append(0)\n",
    "    else:\n",
    "        result.append(1)\n",
    "result = np.array(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9615384615384616\n",
      "Recall: 1.0\n"
     ]
    }
   ],
   "source": [
    "tp = 0\n",
    "fp = 0\n",
    "tn = 0\n",
    "fn = 0\n",
    "for i in np.arange(result.shape[0]):\n",
    "    if int(result[i]) == 0 and int(test_label[i])==int(result[i]):\n",
    "        tp = tp + 1\n",
    "    if int(result[i]) == 0 and int(test_label[i])!=int(result[i]):\n",
    "        fp = fp + 1\n",
    "    if int(result[i]) == 1 and int(test_label[i])==int(result[i]):\n",
    "        tn = tn + 1\n",
    "    if int(result[i]) == 1 and int(test_label[i])!=int(result[i]):\n",
    "        fn = fn + 1\n",
    "if tp + fp !=0:\n",
    "    print(\"Precision:\", tp/(tp+fp))\n",
    "else:\n",
    "    print(\"Precision:\",np.inf)\n",
    "if tp + fn !=0:\n",
    "    print(\"Recall:\", tp/(tp+fn))\n",
    "else:\n",
    "    print(\"Recall:\",np.inf)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oversampling & Downsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np \n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.metrics import confusion_matrix, classification_report \n",
    "\n",
    "import csv\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying SMOTE Algorithm\n",
    "#Link: https://www.geeksforgeeks.org/ml-handling-imbalanced-data-with-smote-and-near-miss-algorithm-in-python/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('creditcard.csv','rt')as f:\n",
    "    data1 = csv.reader(f)\n",
    "    datax =[]\n",
    "    for row in data1:\n",
    "        datax.append(row)\n",
    "datax = np.array(datax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284808, 31)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datax.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9',\n",
       "       'V10', 'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18',\n",
       "       'V19', 'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27',\n",
       "       'V28', 'Amount', 'Class'], dtype='<U21')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datax[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "datax = np.delete(datax,0,axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284807, 31)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datax.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "datax = datax.astype(np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = datax[:,:30]\n",
    "y = datax[:,30]\n",
    "y = y.astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284807, 30)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of transactions in X_train dataset:  (199364, 30)\n",
      "Number of transactions in y_train dataset:  (199364,)\n",
      "Number of transactions in X_test dataset:  (85443, 30)\n",
      "Number of transactions in y_test dataset:  (85443,)\n"
     ]
    }
   ],
   "source": [
    "# split into 70:30 ration \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0) \n",
    "\n",
    "# describes info about train and test set \n",
    "print(\"Number of transactions in X_train dataset: \", X_train.shape) \n",
    "print(\"Number of transactions in y_train dataset: \", y_train.shape) \n",
    "print(\"Number of transactions in X_test dataset: \", X_test.shape) \n",
    "print(\"Number of transactions in y_test dataset: \", y_test.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method 2 - Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before OverSampling, counts of label '1': 345\n",
      "Before OverSampling, counts of label '0': 199019 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Before OverSampling, counts of label '1': {}\".format(sum(y_train == 1))) \n",
    "print(\"Before OverSampling, counts of label '0': {} \\n\".format(sum(y_train == 0))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aneri\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\utils\\deprecation.py:86: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After OverSampling, the shape of train_X: (398038, 30)\n",
      "After OverSampling, the shape of train_y: (398038,) \n",
      "\n",
      "After OverSampling, counts of label '1': 199019\n",
      "After OverSampling, counts of label '0': 199019\n"
     ]
    }
   ],
   "source": [
    "sm = SMOTE(random_state = 2) \n",
    "X_train_res, y_train_res = sm.fit_sample(X_train, y_train.ravel()) \n",
    "\n",
    "print('After OverSampling, the shape of train_X: {}'.format(X_train_res.shape)) \n",
    "print('After OverSampling, the shape of train_y: {} \\n'.format(y_train_res.shape)) \n",
    "\n",
    "print(\"After OverSampling, counts of label '1': {}\".format(sum(y_train_res == 1))) \n",
    "print(\"After OverSampling, counts of label '0': {}\".format(sum(y_train_res == 0))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     85296\n",
      "           1       0.08      0.87      0.14       147\n",
      "\n",
      "    accuracy                           0.98     85443\n",
      "   macro avg       0.54      0.93      0.56     85443\n",
      "weighted avg       1.00      0.98      0.99     85443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr1 = LogisticRegression() \n",
    "lr1.fit(X_train_res, y_train_res.ravel()) \n",
    "predictions = lr1.predict(X_test) \n",
    "\n",
    "# print classification report \n",
    "print(classification_report(y_test, predictions)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 398038 samples\n",
      "Epoch 1/10\n",
      "398038/398038 [==============================] - 11s 28us/sample - loss: 5.0239 - accuracy: 0.8973\n",
      "Epoch 2/10\n",
      "398038/398038 [==============================] - 8s 21us/sample - loss: 2.9131 - accuracy: 0.9360\n",
      "Epoch 3/10\n",
      "398038/398038 [==============================] - 9s 24us/sample - loss: 2.4560 - accuracy: 0.9480\n",
      "Epoch 4/10\n",
      "398038/398038 [==============================] - 14s 35us/sample - loss: 2.4096 - accuracy: 0.9518\n",
      "Epoch 5/10\n",
      "398038/398038 [==============================] - 9s 24us/sample - loss: 2.3348 - accuracy: 0.9549\n",
      "Epoch 6/10\n",
      "398038/398038 [==============================] - 11s 28us/sample - loss: 2.3065 - accuracy: 0.9566\n",
      "Epoch 7/10\n",
      "398038/398038 [==============================] - 15s 37us/sample - loss: 2.0492 - accuracy: 0.9594\n",
      "Epoch 8/10\n",
      "398038/398038 [==============================] - 11s 27us/sample - loss: 1.9092 - accuracy: 0.9608\n",
      "Epoch 9/10\n",
      "398038/398038 [==============================] - 8s 21us/sample - loss: 1.9331 - accuracy: 0.9610\n",
      "Epoch 10/10\n",
      "398038/398038 [==============================] - 8s 21us/sample - loss: 1.8384 - accuracy: 0.9622\n",
      "(85443, 1)\n"
     ]
    }
   ],
   "source": [
    "#Using Neural Network defined for first part\n",
    "model.fit(X_train_res, y_train_res.ravel(),epochs=10, batch_size=64) \n",
    "predictions = model.predict(X_test) \n",
    "print(predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "predictions=1*(predictions<=0.5)\n",
    "# for i in np.arange(predictions.shape[0]):\n",
    "#     if predictions[i]>0.5:\n",
    "#         result.append(0)\n",
    "#     else:\n",
    "#         result.append(1)\n",
    "# result = np.array(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.02      0.03     85296\n",
      "           1       0.00      0.12      0.00       147\n",
      "\n",
      "    accuracy                           0.02     85443\n",
      "   macro avg       0.46      0.07      0.02     85443\n",
      "weighted avg       0.91      0.02      0.03     85443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print classification report \n",
    "print(classification_report(y_test, predictions)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method 3 - Downsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # print(\"data0 shape:\",data0.shape)\n",
    "# # print(\"data1 shape:\",data1.shape)\n",
    "# print(\"ratio:\",int(data0/data1))\n",
    "# test_data = np.concatenate((data0[:50,:],data1[:50,:]),axis = 0)\n",
    "# test_label = np.concatenate((np.zeros((50,1)),np.ones((50,1))),axis = 0)\n",
    "# print(\"test data\",test_data.shape)\n",
    "# print(\"test label\",test_label.shape)\n",
    "# train_data0 = data0[50:,:]\n",
    "# train_data1 = data1[50:,:]\n",
    "# print(\"train_data0 shape\",train_data0.shape)\n",
    "# print(\"train_data1 shape\",train_data1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 884 samples\n",
      "Epoch 1/10\n",
      "884/884 [==============================] - 0s 47us/sample - loss: 1.2347 - accuracy: 0.9276\n",
      "Epoch 2/10\n",
      "884/884 [==============================] - 0s 45us/sample - loss: 1.1522 - accuracy: 0.9491\n",
      "Epoch 3/10\n",
      "884/884 [==============================] - 0s 45us/sample - loss: 2.5249 - accuracy: 0.8654\n",
      "Epoch 4/10\n",
      "884/884 [==============================] - 0s 55us/sample - loss: 2.2076 - accuracy: 0.8597\n",
      "Epoch 5/10\n",
      "884/884 [==============================] - 0s 52us/sample - loss: 0.9858 - accuracy: 0.9344\n",
      "Epoch 6/10\n",
      "884/884 [==============================] - 0s 45us/sample - loss: 0.6825 - accuracy: 0.9548\n",
      "Epoch 7/10\n",
      "884/884 [==============================] - 0s 61us/sample - loss: 0.6363 - accuracy: 0.9627\n",
      "Epoch 8/10\n",
      "884/884 [==============================] - 0s 73us/sample - loss: 0.5714 - accuracy: 0.9604\n",
      "Epoch 9/10\n",
      "884/884 [==============================] - 0s 52us/sample - loss: 0.4487 - accuracy: 0.9638\n",
      "Epoch 10/10\n",
      "884/884 [==============================] - 0s 55us/sample - loss: 0.5933 - accuracy: 0.9593\n",
      "predict shape: (100, 1)\n",
      "Train on 884 samples\n",
      "Epoch 1/10\n",
      "884/884 [==============================] - 0s 58us/sample - loss: 0.5140 - accuracy: 0.9638\n",
      "Epoch 2/10\n",
      "884/884 [==============================] - 0s 47us/sample - loss: 0.4974 - accuracy: 0.9638\n",
      "Epoch 3/10\n",
      "884/884 [==============================] - 0s 46us/sample - loss: 0.4885 - accuracy: 0.9661\n",
      "Epoch 4/10\n",
      "884/884 [==============================] - 0s 49us/sample - loss: 0.4731 - accuracy: 0.9672\n",
      "Epoch 5/10\n",
      "884/884 [==============================] - 0s 78us/sample - loss: 0.4265 - accuracy: 0.9695\n",
      "Epoch 6/10\n",
      "884/884 [==============================] - 0s 46us/sample - loss: 0.3593 - accuracy: 0.9751\n",
      "Epoch 7/10\n",
      "884/884 [==============================] - 0s 47us/sample - loss: 0.3327 - accuracy: 0.9740\n",
      "Epoch 8/10\n",
      "884/884 [==============================] - 0s 46us/sample - loss: 0.3805 - accuracy: 0.9706\n",
      "Epoch 9/10\n",
      "884/884 [==============================] - 0s 46us/sample - loss: 0.2961 - accuracy: 0.9774\n",
      "Epoch 10/10\n",
      "884/884 [==============================] - 0s 44us/sample - loss: 0.8377 - accuracy: 0.9378\n",
      "predict shape: (100, 1)\n",
      "Train on 884 samples\n",
      "Epoch 1/10\n",
      "884/884 [==============================] - 0s 51us/sample - loss: 0.6012 - accuracy: 0.9525\n",
      "Epoch 2/10\n",
      "884/884 [==============================] - 0s 44us/sample - loss: 0.3769 - accuracy: 0.9740\n",
      "Epoch 3/10\n",
      "884/884 [==============================] - 0s 45us/sample - loss: 0.3072 - accuracy: 0.9808\n",
      "Epoch 4/10\n",
      "884/884 [==============================] - 0s 49us/sample - loss: 0.5243 - accuracy: 0.9593\n",
      "Epoch 5/10\n",
      "884/884 [==============================] - 0s 47us/sample - loss: 0.4086 - accuracy: 0.9729\n",
      "Epoch 6/10\n",
      "884/884 [==============================] - 0s 43us/sample - loss: 0.3656 - accuracy: 0.9729\n",
      "Epoch 7/10\n",
      "884/884 [==============================] - 0s 45us/sample - loss: 0.3759 - accuracy: 0.9729\n",
      "Epoch 8/10\n",
      "884/884 [==============================] - 0s 45us/sample - loss: 0.3683 - accuracy: 0.9729\n",
      "Epoch 9/10\n",
      "884/884 [==============================] - 0s 52us/sample - loss: 0.3208 - accuracy: 0.9774\n",
      "Epoch 10/10\n",
      "884/884 [==============================] - 0s 45us/sample - loss: 0.3308 - accuracy: 0.9808\n",
      "predict shape: (100, 1)\n",
      "Train on 884 samples\n",
      "Epoch 1/10\n",
      "884/884 [==============================] - 0s 51us/sample - loss: 0.2882 - accuracy: 0.9830\n",
      "Epoch 2/10\n",
      "884/884 [==============================] - 0s 45us/sample - loss: 0.2381 - accuracy: 0.9853\n",
      "Epoch 3/10\n",
      "884/884 [==============================] - 0s 53us/sample - loss: 0.2258 - accuracy: 0.9853\n",
      "Epoch 4/10\n",
      "884/884 [==============================] - 0s 52us/sample - loss: 0.2590 - accuracy: 0.9830\n",
      "Epoch 5/10\n",
      "884/884 [==============================] - 0s 55us/sample - loss: 0.2388 - accuracy: 0.9853\n",
      "Epoch 6/10\n",
      "884/884 [==============================] - 0s 46us/sample - loss: 0.3094 - accuracy: 0.9785\n",
      "Epoch 7/10\n",
      "884/884 [==============================] - 0s 50us/sample - loss: 0.2750 - accuracy: 0.9819\n",
      "Epoch 8/10\n",
      "884/884 [==============================] - 0s 49us/sample - loss: 0.2163 - accuracy: 0.9876\n",
      "Epoch 9/10\n",
      "884/884 [==============================] - 0s 51us/sample - loss: 0.1930 - accuracy: 0.9887\n",
      "Epoch 10/10\n",
      "884/884 [==============================] - 0s 53us/sample - loss: 0.1526 - accuracy: 0.9898\n",
      "predict shape: (100, 1)\n",
      "Train on 884 samples\n",
      "Epoch 1/10\n",
      "884/884 [==============================] - 0s 64us/sample - loss: 0.2018 - accuracy: 0.9864\n",
      "Epoch 2/10\n",
      "884/884 [==============================] - 0s 49us/sample - loss: 0.1850 - accuracy: 0.9887\n",
      "Epoch 3/10\n",
      "884/884 [==============================] - 0s 48us/sample - loss: 0.1440 - accuracy: 0.9887\n",
      "Epoch 4/10\n",
      "884/884 [==============================] - 0s 53us/sample - loss: 0.1928 - accuracy: 0.9864\n",
      "Epoch 5/10\n",
      "884/884 [==============================] - 0s 74us/sample - loss: 0.1749 - accuracy: 0.9887\n",
      "Epoch 6/10\n",
      "884/884 [==============================] - 0s 51us/sample - loss: 0.1635 - accuracy: 0.9898\n",
      "Epoch 7/10\n",
      "884/884 [==============================] - 0s 51us/sample - loss: 0.1845 - accuracy: 0.9910\n",
      "Epoch 8/10\n",
      "884/884 [==============================] - 0s 50us/sample - loss: 0.1540 - accuracy: 0.9898\n",
      "Epoch 9/10\n",
      "884/884 [==============================] - 0s 49us/sample - loss: 0.1496 - accuracy: 0.9910\n",
      "Epoch 10/10\n",
      "884/884 [==============================] - 0s 50us/sample - loss: 0.1484 - accuracy: 0.9887\n",
      "predict shape: (100, 1)\n",
      "Train on 1326 samples\n",
      "Epoch 1/10\n",
      "1326/1326 [==============================] - 0s 52us/sample - loss: 0.2101 - accuracy: 0.9872\n",
      "Epoch 2/10\n",
      "1326/1326 [==============================] - 0s 50us/sample - loss: 0.1433 - accuracy: 0.9894\n",
      "Epoch 3/10\n",
      "1326/1326 [==============================] - 0s 53us/sample - loss: 0.1141 - accuracy: 0.9917\n",
      "Epoch 4/10\n",
      "1326/1326 [==============================] - 0s 53us/sample - loss: 0.1233 - accuracy: 0.9879\n",
      "Epoch 5/10\n",
      "1326/1326 [==============================] - 0s 51us/sample - loss: 0.0468 - accuracy: 0.9917\n",
      "Epoch 6/10\n",
      "1326/1326 [==============================] - 0s 52us/sample - loss: 0.4721 - accuracy: 0.9525\n",
      "Epoch 7/10\n",
      "1326/1326 [==============================] - 0s 52us/sample - loss: 0.7345 - accuracy: 0.9427\n",
      "Epoch 8/10\n",
      "1326/1326 [==============================] - 0s 49us/sample - loss: 0.3539 - accuracy: 0.9879\n",
      "Epoch 9/10\n",
      "1326/1326 [==============================] - 0s 45us/sample - loss: 0.5263 - accuracy: 0.9646\n",
      "Epoch 10/10\n",
      "1326/1326 [==============================] - 0s 51us/sample - loss: 0.3054 - accuracy: 0.9811\n",
      "predict shape: (100, 1)\n",
      "Train on 1326 samples\n",
      "Epoch 1/10\n",
      "1326/1326 [==============================] - 0s 63us/sample - loss: 0.3003 - accuracy: 0.9789\n",
      "Epoch 2/10\n",
      "1326/1326 [==============================] - 0s 60us/sample - loss: 0.2000 - accuracy: 0.9842\n",
      "Epoch 3/10\n",
      "1326/1326 [==============================] - 0s 53us/sample - loss: 0.1248 - accuracy: 0.9910\n",
      "Epoch 4/10\n",
      "1326/1326 [==============================] - 0s 48us/sample - loss: 0.1002 - accuracy: 0.9910\n",
      "Epoch 5/10\n",
      "1326/1326 [==============================] - 0s 48us/sample - loss: 0.0686 - accuracy: 0.9932\n",
      "Epoch 6/10\n",
      "1326/1326 [==============================] - 0s 48us/sample - loss: 0.0848 - accuracy: 0.9925\n",
      "Epoch 7/10\n",
      "1326/1326 [==============================] - 0s 45us/sample - loss: 0.0163 - accuracy: 0.9962\n",
      "Epoch 8/10\n",
      "1326/1326 [==============================] - 0s 45us/sample - loss: 0.2862 - accuracy: 0.9638\n",
      "Epoch 9/10\n",
      "1326/1326 [==============================] - 0s 44us/sample - loss: 0.0365 - accuracy: 0.9932\n",
      "Epoch 10/10\n",
      "1326/1326 [==============================] - 0s 53us/sample - loss: 0.0231 - accuracy: 0.9932\n",
      "predict shape: (100, 1)\n",
      "Train on 1326 samples\n",
      "Epoch 1/10\n",
      "1326/1326 [==============================] - 0s 50us/sample - loss: 0.0143 - accuracy: 0.9955\n",
      "Epoch 2/10\n",
      "1326/1326 [==============================] - 0s 45us/sample - loss: 0.0058 - accuracy: 0.9977\n",
      "Epoch 3/10\n",
      "1326/1326 [==============================] - 0s 50us/sample - loss: 0.0105 - accuracy: 0.9955\n",
      "Epoch 4/10\n",
      "1326/1326 [==============================] - 0s 44us/sample - loss: 0.0061 - accuracy: 0.9977\n",
      "Epoch 5/10\n",
      "1326/1326 [==============================] - 0s 53us/sample - loss: 0.2633 - accuracy: 0.9729\n",
      "Epoch 6/10\n",
      "1326/1326 [==============================] - 0s 45us/sample - loss: 0.1740 - accuracy: 0.9834\n",
      "Epoch 7/10\n",
      "1326/1326 [==============================] - 0s 48us/sample - loss: 0.1062 - accuracy: 0.9879\n",
      "Epoch 8/10\n",
      "1326/1326 [==============================] - 0s 51us/sample - loss: 0.0520 - accuracy: 0.9925\n",
      "Epoch 9/10\n",
      "1326/1326 [==============================] - 0s 61us/sample - loss: 0.0078 - accuracy: 0.9962\n",
      "Epoch 10/10\n",
      "1326/1326 [==============================] - 0s 54us/sample - loss: 0.0154 - accuracy: 0.9962\n",
      "predict shape: (100, 1)\n",
      "Train on 1326 samples\n",
      "Epoch 1/10\n",
      "1326/1326 [==============================] - 0s 60us/sample - loss: 0.0080 - accuracy: 0.9977\n",
      "Epoch 2/10\n",
      "1326/1326 [==============================] - 0s 54us/sample - loss: 0.0040 - accuracy: 0.9985\n",
      "Epoch 3/10\n",
      "1326/1326 [==============================] - 0s 74us/sample - loss: 0.0017 - accuracy: 0.9985\n",
      "Epoch 4/10\n",
      "1326/1326 [==============================] - 0s 68us/sample - loss: 7.7707e-04 - accuracy: 0.9992\n",
      "Epoch 5/10\n",
      "1326/1326 [==============================] - 0s 74us/sample - loss: 4.9311e-04 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "1326/1326 [==============================] - 0s 54us/sample - loss: 7.5632e-04 - accuracy: 0.9992\n",
      "Epoch 7/10\n",
      "1326/1326 [==============================] - 0s 65us/sample - loss: 5.2286e-04 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "1326/1326 [==============================] - 0s 54us/sample - loss: 0.0099 - accuracy: 0.9985\n",
      "Epoch 9/10\n",
      "1326/1326 [==============================] - 0s 49us/sample - loss: 0.0077 - accuracy: 0.9985\n",
      "Epoch 10/10\n",
      "1326/1326 [==============================] - 0s 50us/sample - loss: 0.0015 - accuracy: 0.9992\n",
      "predict shape: (100, 1)\n",
      "Train on 1326 samples\n",
      "Epoch 1/10\n",
      "1326/1326 [==============================] - 0s 94us/sample - loss: 0.0494 - accuracy: 0.9910\n",
      "Epoch 2/10\n",
      "1326/1326 [==============================] - 0s 93us/sample - loss: 0.0091 - accuracy: 0.9977\n",
      "Epoch 3/10\n",
      "1326/1326 [==============================] - 0s 75us/sample - loss: 0.0029 - accuracy: 0.9992\n",
      "Epoch 4/10\n",
      "1326/1326 [==============================] - 0s 65us/sample - loss: 0.0028 - accuracy: 0.9992\n",
      "Epoch 5/10\n",
      "1326/1326 [==============================] - 0s 75us/sample - loss: 0.0017 - accuracy: 0.9992\n",
      "Epoch 6/10\n",
      "1326/1326 [==============================] - 0s 80us/sample - loss: 0.1623 - accuracy: 0.9819\n",
      "Epoch 7/10\n",
      "1326/1326 [==============================] - 0s 76us/sample - loss: 0.0735 - accuracy: 0.9947\n",
      "Epoch 8/10\n",
      "1326/1326 [==============================] - 0s 103us/sample - loss: 0.0154 - accuracy: 0.9962\n",
      "Epoch 9/10\n",
      "1326/1326 [==============================] - 0s 117us/sample - loss: 8.4979e-04 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "1326/1326 [==============================] - 0s 80us/sample - loss: 7.7566e-04 - accuracy: 0.9992\n",
      "predict shape: (100, 1)\n",
      "Train on 1768 samples\n",
      "Epoch 1/10\n",
      "1768/1768 [==============================] - 0s 97us/sample - loss: 0.3431 - accuracy: 0.9717\n",
      "Epoch 2/10\n",
      "1768/1768 [==============================] - 0s 85us/sample - loss: 0.1173 - accuracy: 0.9836\n",
      "Epoch 3/10\n",
      "1768/1768 [==============================] - 0s 55us/sample - loss: 0.1246 - accuracy: 0.9853\n",
      "Epoch 4/10\n",
      "1768/1768 [==============================] - 0s 69us/sample - loss: 0.0259 - accuracy: 0.9932\n",
      "Epoch 5/10\n",
      "1768/1768 [==============================] - 0s 60us/sample - loss: 0.0349 - accuracy: 0.9943\n",
      "Epoch 6/10\n",
      "1768/1768 [==============================] - 0s 58us/sample - loss: 0.1648 - accuracy: 0.9757\n",
      "Epoch 7/10\n",
      "1768/1768 [==============================] - 0s 58us/sample - loss: 0.3336 - accuracy: 0.9683\n",
      "Epoch 8/10\n",
      "1768/1768 [==============================] - 0s 59us/sample - loss: 0.1612 - accuracy: 0.9745\n",
      "Epoch 9/10\n",
      "1768/1768 [==============================] - 0s 59us/sample - loss: 0.0034 - accuracy: 0.9994\n",
      "Epoch 10/10\n",
      "1768/1768 [==============================] - 0s 72us/sample - loss: 4.4286e-04 - accuracy: 0.9994\n",
      "predict shape: (100, 1)\n",
      "Train on 1768 samples\n",
      "Epoch 1/10\n",
      "1768/1768 [==============================] - 0s 61us/sample - loss: 1.0735e-04 - accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "1768/1768 [==============================] - 0s 133us/sample - loss: 0.0038 - accuracy: 0.9989\n",
      "Epoch 3/10\n",
      "1768/1768 [==============================] - 0s 171us/sample - loss: 2.3677e-04 - accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "1768/1768 [==============================] - 0s 82us/sample - loss: 1.3419e-04 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "1768/1768 [==============================] - 0s 89us/sample - loss: 1.0285e-04 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "1768/1768 [==============================] - 0s 96us/sample - loss: 1.3908e-04 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "1768/1768 [==============================] - 0s 81us/sample - loss: 1.1031e-04 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "1768/1768 [==============================] - 0s 76us/sample - loss: 8.9097e-05 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "1768/1768 [==============================] - 0s 76us/sample - loss: 8.0125e-05 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "1768/1768 [==============================] - 0s 72us/sample - loss: 7.5998e-05 - accuracy: 1.0000\n",
      "predict shape: (100, 1)\n",
      "Train on 1768 samples\n",
      "Epoch 1/10\n",
      "1768/1768 [==============================] - 0s 100us/sample - loss: 1.1502e-04 - accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "1768/1768 [==============================] - 0s 94us/sample - loss: 8.1104e-05 - accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "1768/1768 [==============================] - 0s 83us/sample - loss: 6.6010e-05 - accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "1768/1768 [==============================] - 0s 82us/sample - loss: 1.6264e-04 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "1768/1768 [==============================] - 0s 94us/sample - loss: 0.0015 - accuracy: 0.9989\n",
      "Epoch 6/10\n",
      "1768/1768 [==============================] - 0s 93us/sample - loss: 3.6570e-05 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "1768/1768 [==============================] - 0s 101us/sample - loss: 3.6379e-05 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "1768/1768 [==============================] - 0s 222us/sample - loss: 3.8981e-05 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "1768/1768 [==============================] - 0s 117us/sample - loss: 3.5355e-05 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "1768/1768 [==============================] - 0s 118us/sample - loss: 3.3432e-05 - accuracy: 1.0000\n",
      "predict shape: (100, 1)\n",
      "Train on 1768 samples\n",
      "Epoch 1/10\n",
      "1768/1768 [==============================] - 0s 80us/sample - loss: 3.6269e-05 - accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "1768/1768 [==============================] - 0s 81us/sample - loss: 3.5340e-05 - accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "1768/1768 [==============================] - 0s 107us/sample - loss: 3.2272e-05 - accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "1768/1768 [==============================] - 0s 84us/sample - loss: 3.1448e-05 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "1768/1768 [==============================] - 0s 76us/sample - loss: 2.9606e-05 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "1768/1768 [==============================] - 0s 57us/sample - loss: 3.3937e-05 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "1768/1768 [==============================] - 0s 54us/sample - loss: 3.0664e-05 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "1768/1768 [==============================] - 0s 65us/sample - loss: 2.7736e-05 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "1768/1768 [==============================] - 0s 70us/sample - loss: 3.3642e-05 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "1768/1768 [==============================] - 0s 60us/sample - loss: 5.5925e-05 - accuracy: 1.0000\n",
      "predict shape: (100, 1)\n",
      "Train on 1768 samples\n",
      "Epoch 1/10\n",
      "1768/1768 [==============================] - 0s 76us/sample - loss: 3.9836e-05 - accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "1768/1768 [==============================] - 0s 56us/sample - loss: 2.9300e-05 - accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "1768/1768 [==============================] - 0s 67us/sample - loss: 2.4724e-05 - accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "1768/1768 [==============================] - 0s 55us/sample - loss: 2.6339e-05 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "1768/1768 [==============================] - 0s 64us/sample - loss: 2.6610e-05 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "1768/1768 [==============================] - 0s 63us/sample - loss: 2.6383e-05 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "1768/1768 [==============================] - 0s 75us/sample - loss: 3.1084e-05 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "1768/1768 [==============================] - 0s 53us/sample - loss: 2.4881e-05 - accuracy: 1.0000\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1768/1768 [==============================] - 0s 51us/sample - loss: 2.1991e-05 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "1768/1768 [==============================] - 0s 46us/sample - loss: 2.2098e-05 - accuracy: 1.0000\n",
      "predict shape: (100, 1)\n",
      "Train on 2210 samples\n",
      "Epoch 1/10\n",
      "2210/2210 [==============================] - 0s 44us/sample - loss: 0.0617 - accuracy: 0.9932\n",
      "Epoch 2/10\n",
      "2210/2210 [==============================] - 0s 44us/sample - loss: 0.8553 - accuracy: 0.9443\n",
      "Epoch 3/10\n",
      "2210/2210 [==============================] - 0s 58us/sample - loss: 3.0830 - accuracy: 0.9090\n",
      "Epoch 4/10\n",
      "2210/2210 [==============================] - 0s 55us/sample - loss: 0.8469 - accuracy: 0.9529\n",
      "Epoch 5/10\n",
      "2210/2210 [==============================] - 0s 51us/sample - loss: 0.2533 - accuracy: 0.9792\n",
      "Epoch 6/10\n",
      "2210/2210 [==============================] - 0s 50us/sample - loss: 0.0461 - accuracy: 0.9946\n",
      "Epoch 7/10\n",
      "2210/2210 [==============================] - 0s 56us/sample - loss: 0.0090 - accuracy: 0.9986\n",
      "Epoch 8/10\n",
      "2210/2210 [==============================] - 0s 46us/sample - loss: 0.0019 - accuracy: 0.9991\n",
      "Epoch 9/10\n",
      "2210/2210 [==============================] - 0s 52us/sample - loss: 0.0172 - accuracy: 0.9964\n",
      "Epoch 10/10\n",
      "2210/2210 [==============================] - 0s 71us/sample - loss: 0.0025 - accuracy: 0.9991\n",
      "predict shape: (100, 1)\n",
      "Train on 2210 samples\n",
      "Epoch 1/10\n",
      "2210/2210 [==============================] - 0s 51us/sample - loss: 0.0013 - accuracy: 0.9995\n",
      "Epoch 2/10\n",
      "2210/2210 [==============================] - 0s 46us/sample - loss: 0.0023 - accuracy: 0.9991\n",
      "Epoch 3/10\n",
      "2210/2210 [==============================] - 0s 53us/sample - loss: 0.0042 - accuracy: 0.9991\n",
      "Epoch 4/10\n",
      "2210/2210 [==============================] - 0s 70us/sample - loss: 0.0018 - accuracy: 0.9995\n",
      "Epoch 5/10\n",
      "2210/2210 [==============================] - 0s 63us/sample - loss: 9.8111e-04 - accuracy: 0.9995\n",
      "Epoch 6/10\n",
      "2210/2210 [==============================] - 0s 61us/sample - loss: 3.8646e-04 - accuracy: 0.9995\n",
      "Epoch 7/10\n",
      "2210/2210 [==============================] - 0s 66us/sample - loss: 1.9487e-04 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "2210/2210 [==============================] - 0s 64us/sample - loss: 2.0731e-04 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "2210/2210 [==============================] - 0s 61us/sample - loss: 1.4596e-04 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "2210/2210 [==============================] - 0s 57us/sample - loss: 0.0019 - accuracy: 0.9995\n",
      "predict shape: (100, 1)\n",
      "Train on 2210 samples\n",
      "Epoch 1/10\n",
      "2210/2210 [==============================] - 0s 49us/sample - loss: 0.0252 - accuracy: 0.9946\n",
      "Epoch 2/10\n",
      "2210/2210 [==============================] - 0s 52us/sample - loss: 1.4671e-05 - accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "2210/2210 [==============================] - 0s 55us/sample - loss: 1.3790e-05 - accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "2210/2210 [==============================] - 0s 61us/sample - loss: 1.2942e-05 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "2210/2210 [==============================] - 0s 45us/sample - loss: 1.2192e-05 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "2210/2210 [==============================] - 0s 46us/sample - loss: 1.1510e-05 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "2210/2210 [==============================] - 0s 42us/sample - loss: 1.0878e-05 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "2210/2210 [==============================] - 0s 44us/sample - loss: 1.0446e-05 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "2210/2210 [==============================] - 0s 43us/sample - loss: 9.7386e-06 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "2210/2210 [==============================] - 0s 43us/sample - loss: 9.2175e-06 - accuracy: 1.0000\n",
      "predict shape: (100, 1)\n",
      "Train on 2210 samples\n",
      "Epoch 1/10\n",
      "2210/2210 [==============================] - 0s 44us/sample - loss: 8.7472e-06 - accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "2210/2210 [==============================] - 0s 44us/sample - loss: 8.3075e-06 - accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "2210/2210 [==============================] - 0s 87us/sample - loss: 7.8946e-06 - accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "2210/2210 [==============================] - 0s 63us/sample - loss: 7.5115e-06 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "2210/2210 [==============================] - 0s 57us/sample - loss: 7.1653e-06 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "2210/2210 [==============================] - 0s 56us/sample - loss: 6.8504e-06 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "2210/2210 [==============================] - 0s 45us/sample - loss: 6.6061e-06 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "2210/2210 [==============================] - 0s 45us/sample - loss: 6.4259e-06 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "2210/2210 [==============================] - 0s 46us/sample - loss: 6.3204e-06 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "2210/2210 [==============================] - 0s 49us/sample - loss: 6.3112e-06 - accuracy: 1.0000\n",
      "predict shape: (100, 1)\n",
      "Train on 2210 samples\n",
      "Epoch 1/10\n",
      "2210/2210 [==============================] - 0s 48us/sample - loss: 6.2700e-06 - accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "2210/2210 [==============================] - 0s 61us/sample - loss: 6.3112e-06 - accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "2210/2210 [==============================] - 0s 63us/sample - loss: 6.4371e-06 - accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "2210/2210 [==============================] - 0s 45us/sample - loss: 6.2926e-06 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "2210/2210 [==============================] - 0s 43us/sample - loss: 6.1018e-06 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "2210/2210 [==============================] - 0s 41us/sample - loss: 6.3443e-06 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "2210/2210 [==============================] - 0s 45us/sample - loss: 6.2308e-06 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "2210/2210 [==============================] - 0s 44us/sample - loss: 6.2860e-06 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "2210/2210 [==============================] - 0s 59us/sample - loss: 6.1858e-06 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "2210/2210 [==============================] - 0s 44us/sample - loss: 5.9992e-06 - accuracy: 1.0000\n",
      "predict shape: (100, 1)\n",
      "Train on 2652 samples\n",
      "Epoch 1/10\n",
      "2652/2652 [==============================] - 0s 48us/sample - loss: 8.7964 - accuracy: 0.8379\n",
      "Epoch 2/10\n",
      "2652/2652 [==============================] - 0s 64us/sample - loss: 0.7251 - accuracy: 0.9502\n",
      "Epoch 3/10\n",
      "2652/2652 [==============================] - 0s 48us/sample - loss: 0.2814 - accuracy: 0.9815\n",
      "Epoch 4/10\n",
      "2652/2652 [==============================] - 0s 49us/sample - loss: 0.2270 - accuracy: 0.9834\n",
      "Epoch 5/10\n",
      "2652/2652 [==============================] - 0s 51us/sample - loss: 0.3026 - accuracy: 0.9804\n",
      "Epoch 6/10\n",
      "2652/2652 [==============================] - 0s 50us/sample - loss: 0.1914 - accuracy: 0.9815\n",
      "Epoch 7/10\n",
      "2652/2652 [==============================] - 0s 50us/sample - loss: 0.0408 - accuracy: 0.9970\n",
      "Epoch 8/10\n",
      "2652/2652 [==============================] - 0s 49us/sample - loss: 0.0019 - accuracy: 0.9989\n",
      "Epoch 9/10\n",
      "2652/2652 [==============================] - 0s 54us/sample - loss: 3.6183e-04 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "2652/2652 [==============================] - 0s 52us/sample - loss: 1.9906e-04 - accuracy: 1.0000\n",
      "predict shape: (100, 1)\n",
      "Train on 2652 samples\n",
      "Epoch 1/10\n",
      "2652/2652 [==============================] - 0s 81us/sample - loss: 6.0471e-04 - accuracy: 0.9996s - loss: 4.2964e-04 - accuracy: \n",
      "Epoch 2/10\n",
      "2652/2652 [==============================] - 0s 75us/sample - loss: 0.0091 - accuracy: 0.9962\n",
      "Epoch 3/10\n",
      "2652/2652 [==============================] - 0s 49us/sample - loss: 1.6213e-04 - accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "2652/2652 [==============================] - 0s 46us/sample - loss: 8.0619e-04 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "2652/2652 [==============================] - 0s 44us/sample - loss: 1.9819e-04 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "2652/2652 [==============================] - 0s 50us/sample - loss: 1.2784e-04 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "2652/2652 [==============================] - 0s 65us/sample - loss: 8.9262e-05 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "2652/2652 [==============================] - 0s 44us/sample - loss: 1.7438e-04 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "2652/2652 [==============================] - 0s 63us/sample - loss: 6.7510e-04 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "2652/2652 [==============================] - 0s 44us/sample - loss: 1.5115e-04 - accuracy: 1.0000\n",
      "predict shape: (100, 1)\n",
      "Train on 2652 samples\n",
      "Epoch 1/10\n",
      "2652/2652 [==============================] - 0s 59us/sample - loss: 8.9881e-05 - accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "2652/2652 [==============================] - 0s 50us/sample - loss: 6.7584e-05 - accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "2652/2652 [==============================] - 0s 45us/sample - loss: 4.5007e-04 - accuracy: 0.9996\n",
      "Epoch 4/10\n",
      "2652/2652 [==============================] - 0s 61us/sample - loss: 0.0490 - accuracy: 0.9913\n",
      "Epoch 5/10\n",
      "2652/2652 [==============================] - 0s 45us/sample - loss: 0.0496 - accuracy: 0.9951\n",
      "Epoch 6/10\n",
      "2652/2652 [==============================] - 0s 47us/sample - loss: 0.5708 - accuracy: 0.9612\n",
      "Epoch 7/10\n",
      "2652/2652 [==============================] - 0s 55us/sample - loss: 0.2510 - accuracy: 0.9811\n",
      "Epoch 8/10\n",
      "2652/2652 [==============================] - 0s 46us/sample - loss: 0.0479 - accuracy: 0.9955\n",
      "Epoch 9/10\n",
      "2652/2652 [==============================] - 0s 43us/sample - loss: 0.0054 - accuracy: 0.9989\n",
      "Epoch 10/10\n",
      "2652/2652 [==============================] - 0s 46us/sample - loss: 0.3572 - accuracy: 0.9744\n",
      "predict shape: (100, 1)\n",
      "Train on 2652 samples\n",
      "Epoch 1/10\n",
      "2652/2652 [==============================] - 0s 44us/sample - loss: 8.5622e-06 - accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "2652/2652 [==============================] - 0s 45us/sample - loss: 7.3436e-06 - accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "2652/2652 [==============================] - 0s 55us/sample - loss: 7.1409e-06 - accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "2652/2652 [==============================] - 0s 51us/sample - loss: 6.9607e-06 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "2652/2652 [==============================] - 0s 45us/sample - loss: 6.7482e-06 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "2652/2652 [==============================] - 0s 46us/sample - loss: 6.5614e-06 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "2652/2652 [==============================] - 0s 52us/sample - loss: 6.3895e-06 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "2652/2652 [==============================] - 0s 58us/sample - loss: 6.1798e-06 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "2652/2652 [==============================] - 0s 47us/sample - loss: 6.0177e-06 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "2652/2652 [==============================] - 0s 60us/sample - loss: 5.8263e-06 - accuracy: 1.0000\n",
      "predict shape: (100, 1)\n",
      "Train on 2652 samples\n",
      "Epoch 1/10\n",
      "2652/2652 [==============================] - 0s 65us/sample - loss: 5.6456e-06 - accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "2652/2652 [==============================] - 0s 46us/sample - loss: 5.4745e-06 - accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "2652/2652 [==============================] - 0s 65us/sample - loss: 5.3070e-06 - accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "2652/2652 [==============================] - 0s 55us/sample - loss: 5.1416e-06 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "2652/2652 [==============================] - 0s 51us/sample - loss: 4.9878e-06 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "2652/2652 [==============================] - 0s 53us/sample - loss: 4.8271e-06 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "2652/2652 [==============================] - 0s 59us/sample - loss: 4.6707e-06 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "2652/2652 [==============================] - 0s 55us/sample - loss: 4.5173e-06 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "2652/2652 [==============================] - 0s 114us/sample - loss: 4.3733e-06 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "2652/2652 [==============================] - 0s 76us/sample - loss: 4.2231e-06 - accuracy: 1.0000\n",
      "predict shape: (100, 1)\n",
      "Train on 3094 samples\n",
      "Epoch 1/10\n",
      "3094/3094 [==============================] - 0s 74us/sample - loss: 0.3547 - accuracy: 0.9851\n",
      "Epoch 2/10\n",
      "3094/3094 [==============================] - 0s 57us/sample - loss: 1.6781 - accuracy: 0.9247\n",
      "Epoch 3/10\n",
      "3094/3094 [==============================] - 0s 93us/sample - loss: 0.1727 - accuracy: 0.9887\n",
      "Epoch 4/10\n",
      "3094/3094 [==============================] - 0s 67us/sample - loss: 0.3195 - accuracy: 0.9771\n",
      "Epoch 5/10\n",
      "3094/3094 [==============================] - 0s 45us/sample - loss: 0.1775 - accuracy: 0.9855\n",
      "Epoch 6/10\n",
      "3094/3094 [==============================] - 0s 65us/sample - loss: 0.0306 - accuracy: 0.9958\n",
      "Epoch 7/10\n",
      "3094/3094 [==============================] - 0s 46us/sample - loss: 0.0155 - accuracy: 0.9990\n",
      "Epoch 8/10\n",
      "3094/3094 [==============================] - 0s 67us/sample - loss: 0.0250 - accuracy: 0.9964\n",
      "Epoch 9/10\n",
      "3094/3094 [==============================] - 0s 51us/sample - loss: 5.2653e-04 - accuracy: 0.9997\n",
      "Epoch 10/10\n",
      "3094/3094 [==============================] - 0s 45us/sample - loss: 0.0363 - accuracy: 0.9961\n",
      "predict shape: (100, 1)\n",
      "Train on 3094 samples\n",
      "Epoch 1/10\n",
      "3094/3094 [==============================] - 0s 74us/sample - loss: 0.0024 - accuracy: 0.9994\n",
      "Epoch 2/10\n",
      "3094/3094 [==============================] - 0s 57us/sample - loss: 2.2302e-04 - accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "3094/3094 [==============================] - 0s 63us/sample - loss: 3.5432e-05 - accuracy: 1.0000s - loss: 8.2444e-09 - accuracy: 1.\n",
      "Epoch 4/10\n",
      "3094/3094 [==============================] - 0s 51us/sample - loss: 0.0068 - accuracy: 0.9981\n",
      "Epoch 5/10\n",
      "3094/3094 [==============================] - 0s 47us/sample - loss: 0.0053 - accuracy: 0.9990\n",
      "Epoch 6/10\n",
      "3094/3094 [==============================] - 0s 54us/sample - loss: 0.0022 - accuracy: 0.9994\n",
      "Epoch 7/10\n",
      "3094/3094 [==============================] - 0s 59us/sample - loss: 0.0014 - accuracy: 0.9997\n",
      "Epoch 8/10\n",
      "3094/3094 [==============================] - 0s 54us/sample - loss: 5.2598e-05 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "3094/3094 [==============================] - 0s 53us/sample - loss: 2.3929e-05 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "3094/3094 [==============================] - 0s 51us/sample - loss: 1.6346e-05 - accuracy: 1.0000\n",
      "predict shape: (100, 1)\n",
      "Train on 3094 samples\n",
      "Epoch 1/10\n",
      "3094/3094 [==============================] - 0s 55us/sample - loss: 1.3055e-05 - accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "3094/3094 [==============================] - 0s 48us/sample - loss: 1.0217e-05 - accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "3094/3094 [==============================] - 0s 44us/sample - loss: 8.6682e-06 - accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "3094/3094 [==============================] - 0s 43us/sample - loss: 7.5404e-06 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "3094/3094 [==============================] - 0s 42us/sample - loss: 6.6617e-06 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "3094/3094 [==============================] - 0s 43us/sample - loss: 5.9468e-06 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "3094/3094 [==============================] - 0s 42us/sample - loss: 5.4015e-06 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "3094/3094 [==============================] - 0s 42us/sample - loss: 4.9479e-06 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "3094/3094 [==============================] - 0s 42us/sample - loss: 4.5765e-06 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "3094/3094 [==============================] - 0s 41us/sample - loss: 4.3982e-06 - accuracy: 1.0000\n",
      "predict shape: (100, 1)\n",
      "Train on 3094 samples\n",
      "Epoch 1/10\n",
      "3094/3094 [==============================] - 0s 42us/sample - loss: 4.3732e-06 - accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "3094/3094 [==============================] - 0s 44us/sample - loss: 7.6450e-06 - accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "3094/3094 [==============================] - 0s 45us/sample - loss: 6.1845e-06 - accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "3094/3094 [==============================] - 0s 46us/sample - loss: 5.3418e-06 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "3094/3094 [==============================] - 0s 42us/sample - loss: 4.6498e-06 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "3094/3094 [==============================] - 0s 40us/sample - loss: 4.2712e-06 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "3094/3094 [==============================] - 0s 41us/sample - loss: 4.0319e-06 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "3094/3094 [==============================] - 0s 40us/sample - loss: 4.2671e-06 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "3094/3094 [==============================] - 0s 45us/sample - loss: 4.4027e-06 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "3094/3094 [==============================] - 0s 50us/sample - loss: 4.0382e-06 - accuracy: 1.0000\n",
      "predict shape: (100, 1)\n",
      "Train on 3094 samples\n",
      "Epoch 1/10\n",
      "3094/3094 [==============================] - 0s 44us/sample - loss: 3.8938e-06 - accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "3094/3094 [==============================] - 0s 40us/sample - loss: 4.2154e-06 - accuracy: 1.0000\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3094/3094 [==============================] - 0s 41us/sample - loss: 4.1668e-06 - accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "3094/3094 [==============================] - 0s 40us/sample - loss: 3.7341e-06 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "3094/3094 [==============================] - 0s 41us/sample - loss: 4.8849e-06 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "3094/3094 [==============================] - 0s 44us/sample - loss: 6.1177e-06 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "3094/3094 [==============================] - 0s 45us/sample - loss: 4.4616e-06 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "3094/3094 [==============================] - 0s 46us/sample - loss: 3.6383e-06 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "3094/3094 [==============================] - 0s 41us/sample - loss: 3.4777e-06 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "3094/3094 [==============================] - 0s 43us/sample - loss: 3.6031e-06 - accuracy: 1.0000\n",
      "predict shape: (100, 1)\n",
      "Train on 3536 samples\n",
      "Epoch 1/10\n",
      "3536/3536 [==============================] - 0s 53us/sample - loss: 3.7668e-06 - accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "3536/3536 [==============================] - 0s 41us/sample - loss: 3.1439e-06 - accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "3536/3536 [==============================] - 0s 41us/sample - loss: 4.7482e-06 - accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "3536/3536 [==============================] - 0s 51us/sample - loss: 3.4207e-06 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "3536/3536 [==============================] - 0s 47us/sample - loss: 4.9861e-06 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "3536/3536 [==============================] - 0s 41us/sample - loss: 4.0855e-05 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "3536/3536 [==============================] - 0s 43us/sample - loss: 3.1726 - accuracy: 0.9157\n",
      "Epoch 8/10\n",
      "3536/3536 [==============================] - 0s 42us/sample - loss: 0.8092 - accuracy: 0.9559\n",
      "Epoch 9/10\n",
      "3536/3536 [==============================] - 0s 44us/sample - loss: 0.0095 - accuracy: 0.9975\n",
      "Epoch 10/10\n",
      "3536/3536 [==============================] - 0s 41us/sample - loss: 4.9139e-04 - accuracy: 0.9997\n",
      "predict shape: (100, 1)\n",
      "Train on 3536 samples\n",
      "Epoch 1/10\n",
      "3536/3536 [==============================] - 0s 45us/sample - loss: 1.1277e-04 - accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "3536/3536 [==============================] - 0s 59us/sample - loss: 0.0162 - accuracy: 0.9975\n",
      "Epoch 3/10\n",
      "3536/3536 [==============================] - 0s 60us/sample - loss: 8.9529e-04 - accuracy: 0.9994\n",
      "Epoch 4/10\n",
      "3536/3536 [==============================] - 0s 52us/sample - loss: 2.3128e-04 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "3536/3536 [==============================] - 0s 66us/sample - loss: 0.0011 - accuracy: 0.9994\n",
      "Epoch 6/10\n",
      "3536/3536 [==============================] - 0s 92us/sample - loss: 4.6714e-05 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "3536/3536 [==============================] - 0s 125us/sample - loss: 3.3490e-05 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "3536/3536 [==============================] - 0s 99us/sample - loss: 2.6982e-05 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "3536/3536 [==============================] - 0s 67us/sample - loss: 2.3116e-05 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "3536/3536 [==============================] - 0s 75us/sample - loss: 2.1235e-05 - accuracy: 1.0000\n",
      "predict shape: (100, 1)\n",
      "Train on 3536 samples\n",
      "Epoch 1/10\n",
      "3536/3536 [==============================] - 0s 59us/sample - loss: 2.5991e-05 - accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "3536/3536 [==============================] - 0s 59us/sample - loss: 3.0295e-05 - accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "3536/3536 [==============================] - 0s 109us/sample - loss: 3.2631e-05 - accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "3536/3536 [==============================] - 0s 129us/sample - loss: 2.4271e-05 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "3536/3536 [==============================] - 0s 107us/sample - loss: 2.0180e-05 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "3536/3536 [==============================] - 0s 77us/sample - loss: 1.3438e-04 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "3536/3536 [==============================] - 0s 66us/sample - loss: 2.6945e-04 - accuracy: 0.9997\n",
      "Epoch 8/10\n",
      "3536/3536 [==============================] - 0s 82us/sample - loss: 1.5960e-05 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "3536/3536 [==============================] - 0s 68us/sample - loss: 1.5854e-05 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "3536/3536 [==============================] - 0s 81us/sample - loss: 1.4330e-05 - accuracy: 1.0000\n",
      "predict shape: (100, 1)\n",
      "Train on 3536 samples\n",
      "Epoch 1/10\n",
      "3536/3536 [==============================] - 0s 95us/sample - loss: 1.4716e-05 - accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "3536/3536 [==============================] - 0s 53us/sample - loss: 1.5624e-05 - accuracy: 1.0000s - loss: 2.7025e-05 - accuracy: 1.\n",
      "Epoch 3/10\n",
      "3536/3536 [==============================] - 0s 61us/sample - loss: 1.3766e-05 - accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "3536/3536 [==============================] - 0s 76us/sample - loss: 3.2574e-05 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "3536/3536 [==============================] - 0s 60us/sample - loss: 4.9279e-05 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "3536/3536 [==============================] - 0s 61us/sample - loss: 1.7257e-05 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "3536/3536 [==============================] - 0s 60us/sample - loss: 1.3582e-05 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "3536/3536 [==============================] - 0s 82us/sample - loss: 1.1739e-05 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "3536/3536 [==============================] - 0s 64us/sample - loss: 1.4844e-05 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "3536/3536 [==============================] - 0s 67us/sample - loss: 1.1948e-05 - accuracy: 1.0000\n",
      "predict shape: (100, 1)\n",
      "Train on 3536 samples\n",
      "Epoch 1/10\n",
      "3536/3536 [==============================] - 0s 59us/sample - loss: 1.3506e-05 - accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "3536/3536 [==============================] - 0s 58us/sample - loss: 3.1832e-05 - accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "3536/3536 [==============================] - 0s 66us/sample - loss: 1.3096e-05 - accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "3536/3536 [==============================] - 0s 96us/sample - loss: 1.0471e-05 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "3536/3536 [==============================] - 0s 78us/sample - loss: 1.0416e-05 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "3536/3536 [==============================] - 0s 85us/sample - loss: 1.0319e-05 - accuracy: 1.0000s - loss: 4.8191e-05 - accura\n",
      "Epoch 7/10\n",
      "3536/3536 [==============================] - 0s 98us/sample - loss: 1.0024e-05 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "3536/3536 [==============================] - 0s 99us/sample - loss: 9.5492e-06 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "3536/3536 [==============================] - 0s 68us/sample - loss: 1.0434e-05 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "3536/3536 [==============================] - 0s 90us/sample - loss: 8.5198e-06 - accuracy: 1.0000\n",
      "predict shape: (100, 1)\n",
      "Train on 3978 samples\n",
      "Epoch 1/10\n",
      "3978/3978 [==============================] - 0s 57us/sample - loss: 3.5961 - accuracy: 0.9228\n",
      "Epoch 2/10\n",
      "3978/3978 [==============================] - 0s 74us/sample - loss: 0.5905 - accuracy: 0.9754\n",
      "Epoch 3/10\n",
      "3978/3978 [==============================] - 0s 104us/sample - loss: 0.0223 - accuracy: 0.9982\n",
      "Epoch 4/10\n",
      "3978/3978 [==============================] - 0s 52us/sample - loss: 0.0154 - accuracy: 0.9980\n",
      "Epoch 5/10\n",
      "3978/3978 [==============================] - 0s 63us/sample - loss: 1.6533e-04 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "3978/3978 [==============================] - 0s 90us/sample - loss: 0.0133 - accuracy: 0.9970\n",
      "Epoch 7/10\n",
      "3978/3978 [==============================] - 1s 128us/sample - loss: 2.4700e-04 - accuracy: 0.9997\n",
      "Epoch 8/10\n",
      "3978/3978 [==============================] - 0s 86us/sample - loss: 5.3211e-05 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "3978/3978 [==============================] - 0s 60us/sample - loss: 3.1385e-04 - accuracy: 0.9997\n",
      "Epoch 10/10\n",
      "3978/3978 [==============================] - 0s 60us/sample - loss: 4.2565e-05 - accuracy: 1.0000\n",
      "predict shape: (100, 1)\n",
      "Train on 3978 samples\n",
      "Epoch 1/10\n",
      "3978/3978 [==============================] - 0s 46us/sample - loss: 0.0012 - accuracy: 0.9992\n",
      "Epoch 2/10\n",
      "3978/3978 [==============================] - 0s 44us/sample - loss: 0.0170 - accuracy: 0.9970\n",
      "Epoch 3/10\n",
      "3978/3978 [==============================] - 0s 51us/sample - loss: 2.8939e-05 - accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "3978/3978 [==============================] - 0s 43us/sample - loss: 2.6053e-05 - accuracy: 1.0000\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3978/3978 [==============================] - 0s 45us/sample - loss: 2.3671e-05 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "3978/3978 [==============================] - 0s 46us/sample - loss: 2.1753e-05 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "3978/3978 [==============================] - 0s 55us/sample - loss: 2.0364e-05 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "3978/3978 [==============================] - 0s 68us/sample - loss: 1.9106e-05 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "3978/3978 [==============================] - 0s 59us/sample - loss: 1.8069e-05 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "3978/3978 [==============================] - 0s 49us/sample - loss: 1.7154e-05 - accuracy: 1.0000\n",
      "predict shape: (100, 1)\n",
      "Train on 3978 samples\n",
      "Epoch 1/10\n",
      "3978/3978 [==============================] - 0s 89us/sample - loss: 1.6339e-05 - accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "3978/3978 [==============================] - 0s 73us/sample - loss: 1.5611e-05 - accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "3978/3978 [==============================] - 0s 79us/sample - loss: 1.4962e-05 - accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "3978/3978 [==============================] - 0s 77us/sample - loss: 1.4207e-05 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "3978/3978 [==============================] - 0s 68us/sample - loss: 1.3638e-05 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "3978/3978 [==============================] - 0s 52us/sample - loss: 1.3126e-05 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "3978/3978 [==============================] - 0s 70us/sample - loss: 1.2636e-05 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "3978/3978 [==============================] - 0s 69us/sample - loss: 1.2181e-05 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "3978/3978 [==============================] - 0s 55us/sample - loss: 1.1771e-05 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "3978/3978 [==============================] - 0s 47us/sample - loss: 1.1333e-05 - accuracy: 1.0000\n",
      "predict shape: (100, 1)\n",
      "Train on 3978 samples\n",
      "Epoch 1/10\n",
      "3978/3978 [==============================] - 0s 58us/sample - loss: 1.0930e-05 - accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "3978/3978 [==============================] - 0s 45us/sample - loss: 1.0674e-05 - accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "3978/3978 [==============================] - 0s 50us/sample - loss: 1.0421e-05 - accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "3978/3978 [==============================] - 0s 60us/sample - loss: 1.0188e-05 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "3978/3978 [==============================] - 0s 60us/sample - loss: 1.0250e-05 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "3978/3978 [==============================] - 0s 70us/sample - loss: 1.0123e-05 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "3978/3978 [==============================] - 0s 68us/sample - loss: 9.6558e-06 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "3978/3978 [==============================] - 0s 52us/sample - loss: 9.2981e-06 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "3978/3978 [==============================] - 0s 62us/sample - loss: 9.6677e-06 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "3978/3978 [==============================] - 0s 53us/sample - loss: 1.0393e-05 - accuracy: 1.0000\n",
      "predict shape: (100, 1)\n",
      "Train on 3978 samples\n",
      "Epoch 1/10\n",
      "3978/3978 [==============================] - 0s 75us/sample - loss: 9.5510e-06 - accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "3978/3978 [==============================] - 0s 52us/sample - loss: 8.7804e-06 - accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "3978/3978 [==============================] - 0s 56us/sample - loss: 8.1823e-06 - accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "3978/3978 [==============================] - 0s 49us/sample - loss: 7.9023e-06 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "3978/3978 [==============================] - 0s 47us/sample - loss: 7.6976e-06 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "3978/3978 [==============================] - 0s 52us/sample - loss: 7.1956e-06 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "3978/3978 [==============================] - 0s 43us/sample - loss: 7.2119e-06 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "3978/3978 [==============================] - 0s 54us/sample - loss: 6.9559e-06 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "3978/3978 [==============================] - 0s 50us/sample - loss: 6.5181e-06 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "3978/3978 [==============================] - 0s 54us/sample - loss: 6.1803e-06 - accuracy: 1.0000\n",
      "predict shape: (100, 1)\n",
      "Train on 4420 samples\n",
      "Epoch 1/10\n",
      "4420/4420 [==============================] - 0s 94us/sample - loss: 5.8145e-06 - accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "4420/4420 [==============================] - 0s 93us/sample - loss: 5.6893e-06 - accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "4420/4420 [==============================] - 1s 124us/sample - loss: 5.0772e-06 - accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "4420/4420 [==============================] - 1s 113us/sample - loss: 4.7347e-06 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "4420/4420 [==============================] - 0s 88us/sample - loss: 6.1630e-06 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "4420/4420 [==============================] - 0s 81us/sample - loss: 1.2724e-05 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "4420/4420 [==============================] - 0s 78us/sample - loss: 5.3982e-06 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "4420/4420 [==============================] - 0s 69us/sample - loss: 4.3227e-06 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "4420/4420 [==============================] - 0s 81us/sample - loss: 3.7026e-06 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "4420/4420 [==============================] - 0s 67us/sample - loss: 3.3045e-06 - accuracy: 1.0000\n",
      "predict shape: (100, 1)\n",
      "Train on 4420 samples\n",
      "Epoch 1/10\n",
      "4420/4420 [==============================] - 0s 64us/sample - loss: 3.1394e-06 - accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "4420/4420 [==============================] - 0s 53us/sample - loss: 2.9148e-06 - accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "4420/4420 [==============================] - 0s 69us/sample - loss: 3.5182e-06 - accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "4420/4420 [==============================] - 0s 52us/sample - loss: 3.1258e-06 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "4420/4420 [==============================] - 0s 46us/sample - loss: 2.6449e-06 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "4420/4420 [==============================] - 0s 50us/sample - loss: 2.3827e-06 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "4420/4420 [==============================] - 0s 56us/sample - loss: 2.3016e-06 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "4420/4420 [==============================] - 0s 52us/sample - loss: 2.1902e-06 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "4420/4420 [==============================] - 0s 50us/sample - loss: 2.0558e-06 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "4420/4420 [==============================] - 0s 51us/sample - loss: 2.0086e-06 - accuracy: 1.0000\n",
      "predict shape: (100, 1)\n",
      "Train on 4420 samples\n",
      "Epoch 1/10\n",
      "4420/4420 [==============================] - 0s 55us/sample - loss: 1.7784e-06 - accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "4420/4420 [==============================] - 0s 61us/sample - loss: 1.1021 - accuracy: 0.9618\n",
      "Epoch 3/10\n",
      "4420/4420 [==============================] - 0s 53us/sample - loss: 1.2405 - accuracy: 0.9674\n",
      "Epoch 4/10\n",
      "4420/4420 [==============================] - 0s 59us/sample - loss: 0.0925 - accuracy: 0.9905\n",
      "Epoch 5/10\n",
      "4420/4420 [==============================] - 0s 57us/sample - loss: 0.0347 - accuracy: 0.9957\n",
      "Epoch 6/10\n",
      "4420/4420 [==============================] - 0s 53us/sample - loss: 0.0664 - accuracy: 0.9921\n",
      "Epoch 7/10\n",
      "4420/4420 [==============================] - 0s 83us/sample - loss: 0.0887 - accuracy: 0.9910\n",
      "Epoch 8/10\n",
      "4420/4420 [==============================] - 0s 57us/sample - loss: 0.0709 - accuracy: 0.9959\n",
      "Epoch 9/10\n",
      "4420/4420 [==============================] - 0s 57us/sample - loss: 0.0624 - accuracy: 0.9962\n",
      "Epoch 10/10\n",
      "4420/4420 [==============================] - 0s 85us/sample - loss: 0.0541 - accuracy: 0.9957\n",
      "predict shape: (100, 1)\n",
      "Train on 4420 samples\n",
      "Epoch 1/10\n",
      "4420/4420 [==============================] - 1s 122us/sample - loss: 0.1516 - accuracy: 0.9839\n",
      "Epoch 2/10\n",
      "4420/4420 [==============================] - 0s 89us/sample - loss: 0.0542 - accuracy: 0.9932\n",
      "Epoch 3/10\n",
      "4420/4420 [==============================] - 0s 50us/sample - loss: 0.0377 - accuracy: 0.9959A: 0s - loss: 0.1268 - accuracy: 0.\n",
      "Epoch 4/10\n",
      "4420/4420 [==============================] - 0s 50us/sample - loss: 0.2448 - accuracy: 0.9862\n",
      "Epoch 5/10\n",
      "4420/4420 [==============================] - 0s 61us/sample - loss: 0.0435 - accuracy: 0.9950\n",
      "Epoch 6/10\n",
      "4420/4420 [==============================] - 0s 58us/sample - loss: 0.0210 - accuracy: 0.9971\n",
      "Epoch 7/10\n",
      "4420/4420 [==============================] - 0s 57us/sample - loss: 0.0814 - accuracy: 0.9900\n",
      "Epoch 8/10\n",
      "4420/4420 [==============================] - 0s 55us/sample - loss: 0.0457 - accuracy: 0.9946\n",
      "Epoch 9/10\n",
      "4420/4420 [==============================] - 0s 51us/sample - loss: 0.0014 - accuracy: 0.9995\n",
      "Epoch 10/10\n",
      "4420/4420 [==============================] - 0s 53us/sample - loss: 0.0013 - accuracy: 0.9993\n",
      "predict shape: (100, 1)\n",
      "Train on 4420 samples\n",
      "Epoch 1/10\n",
      "4420/4420 [==============================] - 0s 63us/sample - loss: 0.0499 - accuracy: 0.9939\n",
      "Epoch 2/10\n",
      "4420/4420 [==============================] - 0s 46us/sample - loss: 7.8112e-04 - accuracy: 0.9995\n",
      "Epoch 3/10\n",
      "4420/4420 [==============================] - 0s 46us/sample - loss: 4.2685e-04 - accuracy: 0.9998\n",
      "Epoch 4/10\n",
      "4420/4420 [==============================] - 0s 45us/sample - loss: 0.0696 - accuracy: 0.9925\n",
      "Epoch 5/10\n",
      "4420/4420 [==============================] - 0s 49us/sample - loss: 0.0296 - accuracy: 0.9962\n",
      "Epoch 6/10\n",
      "4420/4420 [==============================] - 0s 44us/sample - loss: 0.0566 - accuracy: 0.9950\n",
      "Epoch 7/10\n",
      "4420/4420 [==============================] - 0s 41us/sample - loss: 2.9474e-04 - accuracy: 0.9998\n",
      "Epoch 8/10\n",
      "4420/4420 [==============================] - 0s 41us/sample - loss: 1.7630e-04 - accuracy: 0.9998\n",
      "Epoch 9/10\n",
      "4420/4420 [==============================] - 0s 46us/sample - loss: 1.1206e-04 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "4420/4420 [==============================] - 0s 57us/sample - loss: 7.8849e-05 - accuracy: 1.0000\n",
      "predict shape: (100, 1)\n"
     ]
    }
   ],
   "source": [
    "#Using Downsampling\n",
    "#Initially the ratio of size is 10:90. We will decrease the training set sizes\n",
    "#and see how the average accuracy changes\n",
    "avg_prec = []\n",
    "for i in np.arange(9):\n",
    "    #preparing training data\n",
    "    size0 = (i+1)*train_data1.shape[0]\n",
    "    size1 = train_data1.shape[0]\n",
    "    np.random.shuffle(train_data0)\n",
    "    np.random.shuffle(train_data1)\n",
    "    train_data = np.concatenate((train_data0[:size0,:],train_data1[:size1]),axis = 0)\n",
    "    train_label = np.concatenate((np.zeros((size0,1)),np.ones((size1,1))),axis = 0)\n",
    "    data = np.concatenate((train_data,train_label),axis=1)\n",
    "    \n",
    "    np.random.shuffle(data)\n",
    "    y_train = data[:,data.shape[1]-1]\n",
    "    x_train = np.delete(data,data.shape[1]-1,axis=1)\n",
    "    \n",
    "    #calculating average accuracy over 5 runs for each training size and ratio\n",
    "    avg = 0\n",
    "    for k in np.arange(5):\n",
    "        history = model.fit(x_train,y_train,epochs=10,batch_size=30)\n",
    "        predict = model.predict(test_data)\n",
    "        print(\"predict shape:\",predict.shape)\n",
    "        result = []\n",
    "        for l in np.arange(predict.shape[0]):\n",
    "            if predict[l]<0.5:\n",
    "                result.append(0)\n",
    "            else:\n",
    "                result.append(1)\n",
    "        result = np.array(result)\n",
    "        tn, fp, fn, tp = confusion_matrix(test_label,result).ravel()#Confusion Matrix takes 0 as negative but in our case 0 is positive class\n",
    "        avg = avg + tn/(tn+fn)\n",
    "    avg_prec.append(avg/5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9615384615384615,\n",
       " 0.9506531204644413,\n",
       " 0.912825469429243,\n",
       " 0.9158249158249158,\n",
       " 0.9259259259259259,\n",
       " 0.9124579124579124,\n",
       " 0.9259259259259259,\n",
       " 0.9259259259259259,\n",
       " 0.8998189919242551]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_prec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a=[0.9259259259259259,\n",
    "#  0.9259259259259259,\n",
    "#  0.9259259259259259,\n",
    "#  0.9259259259259259,\n",
    "#  0.9225589225589225,\n",
    "#  0.909090909090909,\n",
    "#  0.9225589225589225,\n",
    "#  0.9124579124579124,\n",
    "#  0.933048433048433]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
